{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ritza articles This is a collection of articles that our writers write for practice and to showcase our work.","title":"Ritza articles"},{"location":"#ritza-articles","text":"This is a collection of articles that our writers write for practice and to showcase our work.","title":"Ritza articles"},{"location":"best-python-books-for-beginners/","text":"Best Python Books For Beginners Python is a great language for beginners to start learning programming in. Here's a review of the best Python books around in 2021. Learn Python the Hard Way is focused on giving students practical experience through coding exercises from the get go. It is great for people who just want to build projects as soon as possible without a good understanding of the theory behind it. You can buy a copy here for $22.00. Automate the Boring Stuff with Python is one of the top international best sellers for Python 3. It is written for anyone looking to automate boring repetitive tasks as its name suggests and includes challenges at the end of each chapter to make sure you\u2019ve understood the concepts you\u2019ve been taught. The book is great for learning automation but isn\u2019t recommended for people looking to become full Python developers. A copy is available here for $28.00. Python crash course is one of the best selling Python books of all time and it\u2019s for a good reason. The book does a satisfactory job at trying to balance its theoretical and practical parts, giving students an understanding of how the applications they build work the way they do. As of the time of writing of this article you can buy a copy of this book for $21.49 on amazon . Learn Python the Right Way is a modern adaptation of How To Think Like A Computer Scientist with a few tweaks to make the learning experience more easy going. It is part 1 in a Python course that aims to give students both theoretical knowledge and practical experience by applying computer science fundamentals in real world scenarios. The bonus for this book is it's free and available for download or reading on its website . Part 2 of the above mentioned course uses a book called Code with Replit which is a collection of exciting Python projects and games you can build right away with no setup steps using the Replit online IDE. The book leans on the knowledge students would have acquired from part 1 of the course and is written in a detailed step by step nature to ensure you never fall behind. Code with Replit is also for free and available here .","title":"Best Python Books For Beginners"},{"location":"best-python-books-for-beginners/#best-python-books-for-beginners","text":"Python is a great language for beginners to start learning programming in. Here's a review of the best Python books around in 2021. Learn Python the Hard Way is focused on giving students practical experience through coding exercises from the get go. It is great for people who just want to build projects as soon as possible without a good understanding of the theory behind it. You can buy a copy here for $22.00. Automate the Boring Stuff with Python is one of the top international best sellers for Python 3. It is written for anyone looking to automate boring repetitive tasks as its name suggests and includes challenges at the end of each chapter to make sure you\u2019ve understood the concepts you\u2019ve been taught. The book is great for learning automation but isn\u2019t recommended for people looking to become full Python developers. A copy is available here for $28.00. Python crash course is one of the best selling Python books of all time and it\u2019s for a good reason. The book does a satisfactory job at trying to balance its theoretical and practical parts, giving students an understanding of how the applications they build work the way they do. As of the time of writing of this article you can buy a copy of this book for $21.49 on amazon . Learn Python the Right Way is a modern adaptation of How To Think Like A Computer Scientist with a few tweaks to make the learning experience more easy going. It is part 1 in a Python course that aims to give students both theoretical knowledge and practical experience by applying computer science fundamentals in real world scenarios. The bonus for this book is it's free and available for download or reading on its website . Part 2 of the above mentioned course uses a book called Code with Replit which is a collection of exciting Python projects and games you can build right away with no setup steps using the Replit online IDE. The book leans on the knowledge students would have acquired from part 1 of the course and is written in a detailed step by step nature to ensure you never fall behind. Code with Replit is also for free and available here .","title":"Best Python Books For Beginners"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/","text":"Clubhouse summaries : @shl and @jasonfried discuss deadlines This is a summary of a Clubhouse conversation between several people, but predominantly @shl from Gumroad and @jasonfried from Basecamp . \u23f0 Are deadlines good or bad? The conversation started as a debate. \ud83d\udeab No deadlines: Gumroad has no deadlines; people simply take work that looks fun from a queue. \u2705 Deadlines: Basecamp uses deadlines not to put pressure on people but to be explicit about what their \"appetite\" is for any given project. Conclusion: Both agreed that there's no \"One True System\". Many systems can work for you \u2013 pick one that you like and use it. Why are deadlines bad? \ud83d\ude41 Both founders agreed that deadlines are Wrong \u2013 People are bad at estimating how long things take. Stressful \u2013 People often experience high stress because of deadlines. Work expands but timelines remain fixed. This means that deadlines are nearly always stressful \u2013 you can think of them as a suitcase that a traveller is trying to shove more and more luggage into until the seams start to split. Why are deadlines good? \ud83d\ude01 Because estimating is hard, you might spend far longer on a project than is worthwhile. It's useful to think of projects as bets \u2013 you don't know how much value they will provide or if you will finish them in a reasonable time. If you go to a casino, you should usually assign yourself a fixed amount of money. If you're using cash, you might draw $1000 and commit to leaving if it runs out to limit your downside risk. Similarly, deadlines can limit the downside risk that comes from the unknowns in any project. While most companies will try to push harder to get something across the line as a deadline looms, Basecamp rather aggresively cuts scope to fit a given project into an agreed time frame. If the project isn't completed by the deadline, instead of adding more time by default as many other companies do, the default outcome is to drop the project and regard the best as \"lost\". In some cases, a new deadline is assigned (e.g. if more information is uncovered during the allocated time that makes it clear exactly how much more time is needed and what value can be gained), but this is an explicit choice , not the default. How can you stop deadlines causing stress? \ud83e\udd74 The main reason to avoid deadlines is the stress that they cause. Basecamp doesn't associate projects with a pile of work. A \"project\" is only the goal or concept, and the team working on the project figures out what can be done in the allocated time \u2013 not how to get through all the assigned work by the given deadline. You can think of this as giving your team a \"scope hammer\". They can smash things up as necessary to fit tasks into the timeline. Every project has a \"two week version\" and \"one year version\" \u2013 once you've decided your risk appetite for a specific goal, you can carve up or throw out tasks as necessary to fit. Deadlines avoid sunken cost fallacy \ud83c\udf0a If you estimate that something will take you three months, you might find after nine months that you still haven't shipped it. At this point, you've sunk so much time into it that you will default to spending \"just one more month\" on the project. This is bad and a clear case of the sunken cost fallacy, a strong human bias that is irrational. By having strict deadlines, you can avoid this. If a project isn't working out, something is wrong. Rather understand what is wrong and go back to the drawing board for a while, instead of pounding your head against a concrete wall that won't budge and will cause you pain. Does this work for everything? \ud83d\udc8a No. Some things just have to be done. Both founders agreed strongly on this. You can't not file your tax return by the assigned date, even if you underestimated how big a task it was (Basecamp) or it isn't fun (Gumroad). Similarly, for security incidents, severe incidents that cause data loss, or other crises, you simply can't put off dealing with the task at hand. Does this also work for larger corporations? \ud83c\udfd9 Maybe. A place like Microsoft is not going to change over night, but some large corporations are adopting similar systems and they seem to be working. An interesting side note is that startups often try to act more like big companies \u2013 adding more process and more formality, emulating what they see at corporations. In reality, corporations wish they could be more like startups. There is so much value in flexibility, giving your customers what they want and following your gut. Big companies would love to be able to operate like this, but they can't. Enjoy it while it lasts!","title":"**Clubhouse summaries**: @shl and @jasonfried discuss deadlines"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#clubhouse-summaries-shl-and-jasonfried-discuss-deadlines","text":"This is a summary of a Clubhouse conversation between several people, but predominantly @shl from Gumroad and @jasonfried from Basecamp .","title":"Clubhouse summaries: @shl and @jasonfried discuss deadlines"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#are-deadlines-good-or-bad","text":"The conversation started as a debate. \ud83d\udeab No deadlines: Gumroad has no deadlines; people simply take work that looks fun from a queue. \u2705 Deadlines: Basecamp uses deadlines not to put pressure on people but to be explicit about what their \"appetite\" is for any given project. Conclusion: Both agreed that there's no \"One True System\". Many systems can work for you \u2013 pick one that you like and use it.","title":"\u23f0 Are deadlines good or bad?"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#why-are-deadlines-bad","text":"Both founders agreed that deadlines are Wrong \u2013 People are bad at estimating how long things take. Stressful \u2013 People often experience high stress because of deadlines. Work expands but timelines remain fixed. This means that deadlines are nearly always stressful \u2013 you can think of them as a suitcase that a traveller is trying to shove more and more luggage into until the seams start to split.","title":"Why are deadlines bad? \ud83d\ude41"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#why-are-deadlines-good","text":"Because estimating is hard, you might spend far longer on a project than is worthwhile. It's useful to think of projects as bets \u2013 you don't know how much value they will provide or if you will finish them in a reasonable time. If you go to a casino, you should usually assign yourself a fixed amount of money. If you're using cash, you might draw $1000 and commit to leaving if it runs out to limit your downside risk. Similarly, deadlines can limit the downside risk that comes from the unknowns in any project. While most companies will try to push harder to get something across the line as a deadline looms, Basecamp rather aggresively cuts scope to fit a given project into an agreed time frame. If the project isn't completed by the deadline, instead of adding more time by default as many other companies do, the default outcome is to drop the project and regard the best as \"lost\". In some cases, a new deadline is assigned (e.g. if more information is uncovered during the allocated time that makes it clear exactly how much more time is needed and what value can be gained), but this is an explicit choice , not the default.","title":"Why are deadlines good? \ud83d\ude01"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#how-can-you-stop-deadlines-causing-stress","text":"The main reason to avoid deadlines is the stress that they cause. Basecamp doesn't associate projects with a pile of work. A \"project\" is only the goal or concept, and the team working on the project figures out what can be done in the allocated time \u2013 not how to get through all the assigned work by the given deadline. You can think of this as giving your team a \"scope hammer\". They can smash things up as necessary to fit tasks into the timeline. Every project has a \"two week version\" and \"one year version\" \u2013 once you've decided your risk appetite for a specific goal, you can carve up or throw out tasks as necessary to fit.","title":"How can you stop deadlines causing stress? \ud83e\udd74"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#deadlines-avoid-sunken-cost-fallacy","text":"If you estimate that something will take you three months, you might find after nine months that you still haven't shipped it. At this point, you've sunk so much time into it that you will default to spending \"just one more month\" on the project. This is bad and a clear case of the sunken cost fallacy, a strong human bias that is irrational. By having strict deadlines, you can avoid this. If a project isn't working out, something is wrong. Rather understand what is wrong and go back to the drawing board for a while, instead of pounding your head against a concrete wall that won't budge and will cause you pain.","title":"Deadlines avoid sunken cost fallacy \ud83c\udf0a"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#does-this-work-for-everything","text":"No. Some things just have to be done. Both founders agreed strongly on this. You can't not file your tax return by the assigned date, even if you underestimated how big a task it was (Basecamp) or it isn't fun (Gumroad). Similarly, for security incidents, severe incidents that cause data loss, or other crises, you simply can't put off dealing with the task at hand.","title":"Does this work for everything? \ud83d\udc8a"},{"location":"clubhouse-summaries-shl-and-jasonfried-discuss-deadlines/#does-this-also-work-for-larger-corporations","text":"Maybe. A place like Microsoft is not going to change over night, but some large corporations are adopting similar systems and they seem to be working. An interesting side note is that startups often try to act more like big companies \u2013 adding more process and more formality, emulating what they see at corporations. In reality, corporations wish they could be more like startups. There is so much value in flexibility, giving your customers what they want and following your gut. Big companies would love to be able to operate like this, but they can't. Enjoy it while it lasts!","title":"Does this also work for larger corporations? \ud83c\udfd9"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/","text":"DEV.to vs Medium vs Hashnode vs Hackernoon Introduction So, you want to publish tutorials or technical articles, perhaps for yourself or for a brand you manage. Creating and hosting your own blog from scratch is no easy task; luckily there are pre-built and managed platforms where you can publish your work without having to run your own site. These platforms mostly let you create an account and start writing. From there, they handle distribution and take care of all the other platform management tasks. If you are running your own blog already, it is still a good idea to take advantage of the large communities of these platforms to redistribute your articles and gain more exposure. There is a plethora of blogging platforms to choose from, each with their own advantages and disadvantages. In this article, we aim to make the decision a little easier by comparing the top blogging platforms for developers. Just Tell Me Which to Use If you just want to know which to use and get on with it, you should probably use: Dev.to if you want to exchange knowledge and experience with the largest active developer community, whether you write professionally or not. Hashnode if you want to completely customise your blog page to represent your brand and link your own domain. Hackernoon if you want to work with a professional team of editors and publish to a platform that only accepts high-quality content. Medium if you want to write about general topics and monetise your work. Quick Overview Before we dive into detailed comparisons, here\u2019s a quick overview of each platform. DEv.to Dev.to is one of the largest online communities of software developers. It is a place where developers and aspiring developers meet to share their knowledge and stories. They don\u2019t have paywalls or adverts, but instead make their revenue from sponsors, listings, and the DEV shop. Their text editor uses Markdown formatting with built-in syntax highlighting which makes it easy to embed code snippets, tables and other media. They also have a public API that developers can use to automate their publishing workflow. Medium Medium is an online publishing platform for all kinds of writers and topics. They have a clean look and feel with an easy-to-use text editor. It is a great place for writers to share their content and monetise their articles. They have a very large reader base so with consistent writing and submission to publications, your target audience will find you. As Medium caters to all types of writers, their text editor is plain and simple. However, because they don\u2019t support Markdown and syntax highlighting, it is not the best place for developers to write technical articles where code snippets or tables are needed. They don\u2019t allow API integration, so for redistribution your only route is using their import tool which is much like copy-pasting as you\u2019ll always have to manually tweak the article to work in the Medium editor. They opted for a revenue model where readers have to pay a monthly subscription fee to read articles. This is great if you are writing for an income but it\u2019s not so great if you merely want to freely share knowledge. Hashnode Hashnode is a free blogging platform and community of developers that enables you to publish articles on your domain with a custom blog page. This is a great place to start your personal blog as a developer because you get traffic to your own domain, growing your brand, while your articles get distributed to the Hashnode developer community. Hashnode allows you to completely customise your blog page with built-in features, widgets and integrations. They have also released a custom CSS feature that will allow you even more flexibility as to the look and feel of your blog page. It\u2019s easy to sign up and get started with a custom blog and they promise to be free forever. They don\u2019t support adverts or have a paywall of any kind. They have an easy to use text editor that supports Markdown so code embeds and syntax highlighting is not a problem. They are working on a public API that will enable developers to automate their publishing workflow and they have a GitHub integration where a Markdown version of your article will be pushed to your repo when hitting the publish button. Hackernoon Hackernoon is a technology publishing service that focuses on topics such as software development, startups, artificial intelligence and cryptocurrencies. They originally started as a publication on Medium but decided to move away when Medium adjusted their business model. They have a similar text editor to Medium that does not support Markdown, making it difficult to embed things like tables, and it doesn\u2019t support syntax highlighting. Hackernoon has a lengthy signup process where you choose to write either as an individual or as a brand. The individual option allows you to publish articles for free whereas publishing as a brand will cost you $199 per published article. You will have to jump through a few hoops and work with editors but, because of this, Hackernoon has higher quality content that will help you gain traction as a professional writer when you get published. All articles are subject to approval by their editors before publishing and the process takes up to 4 days. Dev.to vs Medium Dev.to is an online community of developers sharing their developer journey from complete beginners to experts through articles, blog posts and discussions while Medium is a publishing platform for all kinds of writing where short, opinionated posts seem to be prioritised over more lengthy technical articles. Consider Dev.to if you are a developer of any caliber who wishes to connect with other developers whether through sharing knowledge, learning or taking part in discussions. Consider Medium if you want to write more creative or opinionated articles on various topics and want to monetise your work. Dev.to vs Hashnode Dev.to and Hashnode are both blogging platforms that have large developer communities. However, Dev.to is an open-source blogging platform that you can use to build your own (although most people just sign up for an account and publish on the dev.to domain). Hashnode is a proprietary blogging platform that allows you to easily build your own blog page with custom CSS and link it to your own domain name. Consider Dev.to if you want to be part of an open community of developers and publish content on the fast-growing dev.to domain. Consider Hashnode if you want to publish on your own domain while still being able to distribute your content to a developer-focussed community. Dev.to vs Hackernoon Dev.to is an open community where developers can write about anything they wish: they can write technical articles, how-to guides and even start discussions. Hackernoon is a developers\u2019 publication that migrated from Medium to their own platform. They don\u2019t allow you to just post what you like: they are a publication so you submit your articles for review by their editors. Once approved, your article will be published to their reader base. Consider Dev.to if you want an easy place to write and publish without constraints. Consider Hackernoon if you are willing to submit your articles for approval and work on them with editors. The overall quality is higher on Hackernoon because of their approval process so you will likely get more traction if you get published. Hashnode vs Medium Hashnode is a free blogging platform with a large, specifically developer community while Medium is a publication service with the largest existing general audience but some dark monetising patterns that can be off-putting for readers. The other main difference especially for technical writing is that the Hashnode text editor uses Markdown formatting with built-in syntax highlighting where with Medium\u2019s editor, you\u2019ll have to do some hacking to get similar results. Consider Hashnode if you want to specifically write to developers on a free blogging platform. Consider Medium if you want the widest existing general audience, and don't mind that they will be spammed with paywalls and tracking. Hackernoon vs Medium Hackernoon is similar to Medium in that they are both publication platforms where you can submit articles to be published. In fact, Hackernoon started as a publication on Medium but moved to its own (similar) platform. The difference between the two is that Hackernoon is purely a developer\u2019s publication service and their content is free to read and write as a developer, whereas Medium caters to all types of content but they charge their readers a fee to read. Consider Hackernoon if you want to write technical articles and don\u2019t mind working on them with editors. Consider Medium if you want to write about general topics and make an income off your content. Final remarks While each platform has its own advantages and disadvantages, it is up to you to find the one that aligns with your specific needs. You can always choose more than one in order to reach more readers but remember to specify the canonical URL when redistributing your article. All of the above platforms allow you to configure a canonical URL. This will help your domain rank better on Google. If you don\u2019t set the canonical URL, Google sees it as duplicate content.","title":"DEV.to vs Medium vs Hashnode vs Hackernoon"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#devto-vs-medium-vs-hashnode-vs-hackernoon","text":"","title":"DEV.to vs Medium vs Hashnode vs Hackernoon"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#introduction","text":"So, you want to publish tutorials or technical articles, perhaps for yourself or for a brand you manage. Creating and hosting your own blog from scratch is no easy task; luckily there are pre-built and managed platforms where you can publish your work without having to run your own site. These platforms mostly let you create an account and start writing. From there, they handle distribution and take care of all the other platform management tasks. If you are running your own blog already, it is still a good idea to take advantage of the large communities of these platforms to redistribute your articles and gain more exposure. There is a plethora of blogging platforms to choose from, each with their own advantages and disadvantages. In this article, we aim to make the decision a little easier by comparing the top blogging platforms for developers.","title":"Introduction"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#just-tell-me-which-to-use","text":"If you just want to know which to use and get on with it, you should probably use: Dev.to if you want to exchange knowledge and experience with the largest active developer community, whether you write professionally or not. Hashnode if you want to completely customise your blog page to represent your brand and link your own domain. Hackernoon if you want to work with a professional team of editors and publish to a platform that only accepts high-quality content. Medium if you want to write about general topics and monetise your work.","title":"Just Tell Me Which to Use"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#quick-overview","text":"Before we dive into detailed comparisons, here\u2019s a quick overview of each platform.","title":"Quick Overview"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#devto","text":"Dev.to is one of the largest online communities of software developers. It is a place where developers and aspiring developers meet to share their knowledge and stories. They don\u2019t have paywalls or adverts, but instead make their revenue from sponsors, listings, and the DEV shop. Their text editor uses Markdown formatting with built-in syntax highlighting which makes it easy to embed code snippets, tables and other media. They also have a public API that developers can use to automate their publishing workflow.","title":"DEv.to"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#medium","text":"Medium is an online publishing platform for all kinds of writers and topics. They have a clean look and feel with an easy-to-use text editor. It is a great place for writers to share their content and monetise their articles. They have a very large reader base so with consistent writing and submission to publications, your target audience will find you. As Medium caters to all types of writers, their text editor is plain and simple. However, because they don\u2019t support Markdown and syntax highlighting, it is not the best place for developers to write technical articles where code snippets or tables are needed. They don\u2019t allow API integration, so for redistribution your only route is using their import tool which is much like copy-pasting as you\u2019ll always have to manually tweak the article to work in the Medium editor. They opted for a revenue model where readers have to pay a monthly subscription fee to read articles. This is great if you are writing for an income but it\u2019s not so great if you merely want to freely share knowledge.","title":"Medium"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#hashnode","text":"Hashnode is a free blogging platform and community of developers that enables you to publish articles on your domain with a custom blog page. This is a great place to start your personal blog as a developer because you get traffic to your own domain, growing your brand, while your articles get distributed to the Hashnode developer community. Hashnode allows you to completely customise your blog page with built-in features, widgets and integrations. They have also released a custom CSS feature that will allow you even more flexibility as to the look and feel of your blog page. It\u2019s easy to sign up and get started with a custom blog and they promise to be free forever. They don\u2019t support adverts or have a paywall of any kind. They have an easy to use text editor that supports Markdown so code embeds and syntax highlighting is not a problem. They are working on a public API that will enable developers to automate their publishing workflow and they have a GitHub integration where a Markdown version of your article will be pushed to your repo when hitting the publish button.","title":"Hashnode"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#hackernoon","text":"Hackernoon is a technology publishing service that focuses on topics such as software development, startups, artificial intelligence and cryptocurrencies. They originally started as a publication on Medium but decided to move away when Medium adjusted their business model. They have a similar text editor to Medium that does not support Markdown, making it difficult to embed things like tables, and it doesn\u2019t support syntax highlighting. Hackernoon has a lengthy signup process where you choose to write either as an individual or as a brand. The individual option allows you to publish articles for free whereas publishing as a brand will cost you $199 per published article. You will have to jump through a few hoops and work with editors but, because of this, Hackernoon has higher quality content that will help you gain traction as a professional writer when you get published. All articles are subject to approval by their editors before publishing and the process takes up to 4 days.","title":"Hackernoon"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#devto-vs-medium","text":"Dev.to is an online community of developers sharing their developer journey from complete beginners to experts through articles, blog posts and discussions while Medium is a publishing platform for all kinds of writing where short, opinionated posts seem to be prioritised over more lengthy technical articles. Consider Dev.to if you are a developer of any caliber who wishes to connect with other developers whether through sharing knowledge, learning or taking part in discussions. Consider Medium if you want to write more creative or opinionated articles on various topics and want to monetise your work.","title":"Dev.to vs Medium"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#devto-vs-hashnode","text":"Dev.to and Hashnode are both blogging platforms that have large developer communities. However, Dev.to is an open-source blogging platform that you can use to build your own (although most people just sign up for an account and publish on the dev.to domain). Hashnode is a proprietary blogging platform that allows you to easily build your own blog page with custom CSS and link it to your own domain name. Consider Dev.to if you want to be part of an open community of developers and publish content on the fast-growing dev.to domain. Consider Hashnode if you want to publish on your own domain while still being able to distribute your content to a developer-focussed community.","title":"Dev.to vs Hashnode"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#devto-vs-hackernoon","text":"Dev.to is an open community where developers can write about anything they wish: they can write technical articles, how-to guides and even start discussions. Hackernoon is a developers\u2019 publication that migrated from Medium to their own platform. They don\u2019t allow you to just post what you like: they are a publication so you submit your articles for review by their editors. Once approved, your article will be published to their reader base. Consider Dev.to if you want an easy place to write and publish without constraints. Consider Hackernoon if you are willing to submit your articles for approval and work on them with editors. The overall quality is higher on Hackernoon because of their approval process so you will likely get more traction if you get published.","title":"Dev.to vs Hackernoon"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#hashnode-vs-medium","text":"Hashnode is a free blogging platform with a large, specifically developer community while Medium is a publication service with the largest existing general audience but some dark monetising patterns that can be off-putting for readers. The other main difference especially for technical writing is that the Hashnode text editor uses Markdown formatting with built-in syntax highlighting where with Medium\u2019s editor, you\u2019ll have to do some hacking to get similar results. Consider Hashnode if you want to specifically write to developers on a free blogging platform. Consider Medium if you want the widest existing general audience, and don't mind that they will be spammed with paywalls and tracking.","title":"Hashnode vs Medium"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#hackernoon-vs-medium","text":"Hackernoon is similar to Medium in that they are both publication platforms where you can submit articles to be published. In fact, Hackernoon started as a publication on Medium but moved to its own (similar) platform. The difference between the two is that Hackernoon is purely a developer\u2019s publication service and their content is free to read and write as a developer, whereas Medium caters to all types of content but they charge their readers a fee to read. Consider Hackernoon if you want to write technical articles and don\u2019t mind working on them with editors. Consider Medium if you want to write about general topics and make an income off your content.","title":"Hackernoon vs Medium"},{"location":"devto-vs-medium-vs-hashnode-vs-hackernoon/#final-remarks","text":"While each platform has its own advantages and disadvantages, it is up to you to find the one that aligns with your specific needs. You can always choose more than one in order to reach more readers but remember to specify the canonical URL when redistributing your article. All of the above platforms allow you to configure a canonical URL. This will help your domain rank better on Google. If you don\u2019t set the canonical URL, Google sees it as duplicate content.","title":"Final remarks"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/","text":"GraphQL vs. REST vs. SQL vs. gRPC vs. OData vs. MongoDB GraphQL vs. REST GraphQL is a comparatively newer query language/syntax that lets you query an API for specific data through a single endpoint. While REST is an API architectural style or design pattern that describes how APIs should be built. REST APIs typically have multiple endpoints and return a lot more data than necessary for users. Consider GraphQL if you have complex schemas and/or need better performance on queries. Consider REST if you want to build an API with structured querying for a large number of consumers or resource based API. GraphQL vs. SQL GraphQL is a flexible query language that utilizes a type system to efficiently return data with dynamic queries. While SQL(structured query language) is an older, more adopted language standard used specifically for tabular/relational database systems. Consider GraphQL if you want your API to be built on a NoSQL database. Consider SQL if you want a query language for managing relational database systems. GraphQL vs. gRPC GraphQL is a specialized query language that does away with API versioning and provides predictable, single-point data access methods with fields and types. gRPC is a Google developed data exchange technology that uses a binary format for fast data delivery and streaming. Consider GraphQL if you have multiple complex data sources or API architectures you want to aggregate to a single endpoint. Consider gRPC if you want to have rapid communication between internal APIs such as microservices. GraphQL vs. OData GraphQL is a query language that, by showing what queries are available in advance, lets you query only the data you need. While OData is a standardized protocol that defines best practices for building and using REST APIs. Consider GraphQL for a specification with comparatively greater adoption and performance in the case of mobile APIs and newer technologies. Consider OData for a more mature API with a lower barrier to entry that implements the required REST specifications. OData will also allow for a reasonable learning curve for your API consumers. GraphQL vs. MongoDB GraphQL is an API query language and server-side runtime for executing queries with your existing code and data. While MongoDB is a popular NoSQL database that provides storage for unstructured data in a JSON-like format. Consider GraphQL if you want to create a GraphQL API for an existing database system and use a built-in IDE to build and test queries. Consider MongoDB if you're managing and delivering content/data that can require scaling. MongoDB and GraphQL can be used in conjunction. MongoDB vs. SQL MongoDB is a NoSQL database that flexibly stores data using key-value pairs that can include nested key-value pairs or arrays. While SQL is a query language standard for relational databases. SQL databases are more rigid and store data in tables and rows. Consider MongoDB if you want to store loosely structured or unstructured data. Consider SQL if you want to store structured and/or transactional data where expected change or growth is minimal/non-existent. gRPC vs. REST gRPC is a modern Remote Call Procedure framework that uses HTTP2 and a data serializing method for increased performance with communication or storage applications. While REST is architectural model for APIs to follow the HTTP request and response cycle. REST APIs typically use text based (JSON or XML) formats for data. Consider gRPC if you require efficient communication between microservices or cloud services. Consider REST if want a widely used and supported API framework to work with human-readable data. OData vs. REST OData is a web based protocol that defines best practices for building and using REST APIs. REST is a widely adopted architectural style describing how APIs should be built. Consider OData if you want to build a REST API while focusing on the functionality of the API. OData assists in implementing REST specifications. Consider REST if would like to build custom APIs that do not strictly implement REST specifications.","title":"GraphQL vs. REST vs. SQL vs. gRPC vs. OData vs. MongoDB"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb","text":"","title":"GraphQL vs. REST vs. SQL vs. gRPC vs. OData vs. MongoDB"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-rest","text":"GraphQL is a comparatively newer query language/syntax that lets you query an API for specific data through a single endpoint. While REST is an API architectural style or design pattern that describes how APIs should be built. REST APIs typically have multiple endpoints and return a lot more data than necessary for users. Consider GraphQL if you have complex schemas and/or need better performance on queries. Consider REST if you want to build an API with structured querying for a large number of consumers or resource based API.","title":"GraphQL vs. REST"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-sql","text":"GraphQL is a flexible query language that utilizes a type system to efficiently return data with dynamic queries. While SQL(structured query language) is an older, more adopted language standard used specifically for tabular/relational database systems. Consider GraphQL if you want your API to be built on a NoSQL database. Consider SQL if you want a query language for managing relational database systems.","title":"GraphQL vs. SQL"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-grpc","text":"GraphQL is a specialized query language that does away with API versioning and provides predictable, single-point data access methods with fields and types. gRPC is a Google developed data exchange technology that uses a binary format for fast data delivery and streaming. Consider GraphQL if you have multiple complex data sources or API architectures you want to aggregate to a single endpoint. Consider gRPC if you want to have rapid communication between internal APIs such as microservices.","title":"GraphQL vs. gRPC"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-odata","text":"GraphQL is a query language that, by showing what queries are available in advance, lets you query only the data you need. While OData is a standardized protocol that defines best practices for building and using REST APIs. Consider GraphQL for a specification with comparatively greater adoption and performance in the case of mobile APIs and newer technologies. Consider OData for a more mature API with a lower barrier to entry that implements the required REST specifications. OData will also allow for a reasonable learning curve for your API consumers.","title":"GraphQL vs. OData"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#graphql-vs-mongodb","text":"GraphQL is an API query language and server-side runtime for executing queries with your existing code and data. While MongoDB is a popular NoSQL database that provides storage for unstructured data in a JSON-like format. Consider GraphQL if you want to create a GraphQL API for an existing database system and use a built-in IDE to build and test queries. Consider MongoDB if you're managing and delivering content/data that can require scaling. MongoDB and GraphQL can be used in conjunction.","title":"GraphQL vs. MongoDB"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#mongodb-vs-sql","text":"MongoDB is a NoSQL database that flexibly stores data using key-value pairs that can include nested key-value pairs or arrays. While SQL is a query language standard for relational databases. SQL databases are more rigid and store data in tables and rows. Consider MongoDB if you want to store loosely structured or unstructured data. Consider SQL if you want to store structured and/or transactional data where expected change or growth is minimal/non-existent.","title":"MongoDB vs. SQL"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#grpc-vs-rest","text":"gRPC is a modern Remote Call Procedure framework that uses HTTP2 and a data serializing method for increased performance with communication or storage applications. While REST is architectural model for APIs to follow the HTTP request and response cycle. REST APIs typically use text based (JSON or XML) formats for data. Consider gRPC if you require efficient communication between microservices or cloud services. Consider REST if want a widely used and supported API framework to work with human-readable data.","title":"gRPC vs. REST"},{"location":"graphql-vs-rest-vs-sql-vs-grpc-vs-odata-vs-mongodb/#odata-vs-rest","text":"OData is a web based protocol that defines best practices for building and using REST APIs. REST is a widely adopted architectural style describing how APIs should be built. Consider OData if you want to build a REST API while focusing on the functionality of the API. OData assists in implementing REST specifications. Consider REST if would like to build custom APIs that do not strictly implement REST specifications.","title":"OData vs. REST"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/","text":"Heroku vs Netfliy vs Vercel vs GitHub Pages vs Firebase vs Vercel Heroku vs Netlify Heroku is a PaaS provider that offers hosting solutions for backend applications. Most of the popular backend programming languages like Python, Java and Ruby can be deployed on Heroku. Netlify on the other hand provides hosting for static sites and serverless backend services for frontend applications. Consider Heroku if you\u2019re looking to deploy a backend application like a REST API. Consider using Netlify if you want to deploy a static site or add a new feature (serverless function) to an already existing frontend project. Netlify vs Vercel Netlify is a cloud computing company that focuses on providing hosting solutions for frontend applications whilst Vercel is a collaboration and deployment platform for frontend developers. Both companies offer serverless backend services but there are some differences worth noting before choosing your desired service provider. Netlify uses AWS lambda functions for its serverless functions feature and Vercel has a fair usage policy that restricts you from using their services for CPU intensive tasks like machine learning and crypto mining programs. Furthermore, Vercel also requires all commercial usage to be on a paid plan. Consider using Netlify if you\u2019re just starting out and want to serve a commercial site as well as save some buck. Consider Vercel if your project isn\u2019t going to be partly or wholly CPU intensive. GitHub Pages vs Netlify GitHub Pages allows you to host static sites straight from your GitHub repository whilst Netlify is a company solely created to meet static site hosting and serverless backend needs from all popular version control companies. Consider GitHub Pages if you don\u2019t plan on having any dynamic functionality on your site and are using GitHub for version control. You should also consider GitHub Pages if you\u2019re not looking to sign up to a hosting service provider for your static site hosting needs as it uses your GitHub account for this. Consider Netlify if you are not using GitHub for version control or if your site will have some serverless backend features. Firebase vs Netlify Firebase is Google\u2019s platform for creating and hosting web and mobile software while Netlify is predominantly built to host web applications and serverless functions for frontend sites. Both platforms offer serverless functions as a service but firebase\u2019s functions can only be written in JavaScript and TypeScript whereas Netlify functions can also be written in Go on top of the two languages that firebase supports. Netlify also offers teams a chance to collaborate on projects on their platform whereas firebase wasn\u2019t built with teams in mind. Firebase has a built in database (Realtime or Firestore) that comes with it whereas if you want to use a database with Netlify you have to add the FaunaDB to your architecture as an add-on. Consider firebase if you\u2019d like to use a database for your project and don\u2019t want the extra step of adding add-ons to it. Consider using Netlify if you\u2019d like to write your serverless functions in Go. Firebase vs Heroku Firebase is a platform where you can create and host common features for a web or mobile app like authentication, serverless functions and a database in addition to hosting frontend sites. Heroku on the other hand only focuses on providing hosting solutions for backend applications like API\u2019s for example. Consider using firebase if you want to host a frontend site, use serverless functions, add user auth or a database to your project without having to worry about deploying the auth system or database. Consider Heroku if you want to deploy a backend application or host a database. Heroku vs Vercel Heroku is a cloud computing platform that offers backend developers the chance to build and host their applications whilst Vercel is a platform where frontend developers can collaborate and host their static sites. The two provide hosting solutions for different products and Vercel also offers serverless backend services which allow the developer to only worry about writing backend code and not its deployment or server maintenance. Consider Heroku if you\u2019re looking to host a backend application or database and consider Vercel if you\u2019re looking to host a frontend site or deploy a serverless function. Firebase vs Vercel Firebase is a platform where you can host static sites as well as create and host serverless backend features for them whilst Vercel is a team oriented platform for frontend developers that allows them to integrate their changes and host the finished site and serverless functions on their infrastructure. Furthermore, firebase comes with two persistent ready to use databases (Realtime and Firestore) for your project whereas with Vercel you first have to connect to an external database, if you need one which might be in a different region than your app thereby introducing a latency risk. Consider using Firebase if you\u2019re not working as a team or need to get a database working for your project as fast as possible with no latency risk. It is worth noting that Vercel charges you per team member per month so consider Vercel if you\u2019re working as a team and don\u2019t have a tight budget. GitHub Pages vs Vercel GitHub Pages is a free hosting solution for static sites using GitHub for version control while Vercel is a platform for hosting frontend sites from all the popular version control systems. In addition, Vercel also offers serverless backend services to its customers and has a pay as you grow model for the project you\u2019ll be hosting with them. Consider GitHub Pages if you\u2019re looking to deploy a static site for free or don\u2019t want to sign up for another service for your hosting needs as GitHub Pages uses your GitHub account to deploy the site. Consider Vercel if you\u2019re looking to deploy a site which doesn\u2019t use GitHub for version control or want to add serverless functions to your site. GitHub Pages vs Heroku GitHub Pages is a GitHub feature that allows you to freely serve static sites from GitHub repositories whilst Heroku is a cloud platform for hosting dynamic applications written in any of the popular backend programming languages like Ruby, Python, Java etc. Also, GitHub Pages only works with GitHub for version control whereas Heroku is flexible enough to work with all the major version control systems. Consider GitHub Pages if you want to host a static site for free and consider Heroku if you\u2019re looking to host a backend application or database.","title":"Heroku vs Netfliy vs Vercel vs GitHub Pages vs Firebase vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel","text":"","title":"Heroku vs Netfliy vs Vercel vs GitHub Pages vs Firebase vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#heroku-vs-netlify","text":"Heroku is a PaaS provider that offers hosting solutions for backend applications. Most of the popular backend programming languages like Python, Java and Ruby can be deployed on Heroku. Netlify on the other hand provides hosting for static sites and serverless backend services for frontend applications. Consider Heroku if you\u2019re looking to deploy a backend application like a REST API. Consider using Netlify if you want to deploy a static site or add a new feature (serverless function) to an already existing frontend project.","title":"Heroku vs Netlify"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#netlify-vs-vercel","text":"Netlify is a cloud computing company that focuses on providing hosting solutions for frontend applications whilst Vercel is a collaboration and deployment platform for frontend developers. Both companies offer serverless backend services but there are some differences worth noting before choosing your desired service provider. Netlify uses AWS lambda functions for its serverless functions feature and Vercel has a fair usage policy that restricts you from using their services for CPU intensive tasks like machine learning and crypto mining programs. Furthermore, Vercel also requires all commercial usage to be on a paid plan. Consider using Netlify if you\u2019re just starting out and want to serve a commercial site as well as save some buck. Consider Vercel if your project isn\u2019t going to be partly or wholly CPU intensive.","title":"Netlify vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#github-pages-vs-netlify","text":"GitHub Pages allows you to host static sites straight from your GitHub repository whilst Netlify is a company solely created to meet static site hosting and serverless backend needs from all popular version control companies. Consider GitHub Pages if you don\u2019t plan on having any dynamic functionality on your site and are using GitHub for version control. You should also consider GitHub Pages if you\u2019re not looking to sign up to a hosting service provider for your static site hosting needs as it uses your GitHub account for this. Consider Netlify if you are not using GitHub for version control or if your site will have some serverless backend features.","title":"GitHub Pages vs Netlify"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#firebase-vs-netlify","text":"Firebase is Google\u2019s platform for creating and hosting web and mobile software while Netlify is predominantly built to host web applications and serverless functions for frontend sites. Both platforms offer serverless functions as a service but firebase\u2019s functions can only be written in JavaScript and TypeScript whereas Netlify functions can also be written in Go on top of the two languages that firebase supports. Netlify also offers teams a chance to collaborate on projects on their platform whereas firebase wasn\u2019t built with teams in mind. Firebase has a built in database (Realtime or Firestore) that comes with it whereas if you want to use a database with Netlify you have to add the FaunaDB to your architecture as an add-on. Consider firebase if you\u2019d like to use a database for your project and don\u2019t want the extra step of adding add-ons to it. Consider using Netlify if you\u2019d like to write your serverless functions in Go.","title":"Firebase vs Netlify"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#firebase-vs-heroku","text":"Firebase is a platform where you can create and host common features for a web or mobile app like authentication, serverless functions and a database in addition to hosting frontend sites. Heroku on the other hand only focuses on providing hosting solutions for backend applications like API\u2019s for example. Consider using firebase if you want to host a frontend site, use serverless functions, add user auth or a database to your project without having to worry about deploying the auth system or database. Consider Heroku if you want to deploy a backend application or host a database.","title":"Firebase vs Heroku"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#heroku-vs-vercel","text":"Heroku is a cloud computing platform that offers backend developers the chance to build and host their applications whilst Vercel is a platform where frontend developers can collaborate and host their static sites. The two provide hosting solutions for different products and Vercel also offers serverless backend services which allow the developer to only worry about writing backend code and not its deployment or server maintenance. Consider Heroku if you\u2019re looking to host a backend application or database and consider Vercel if you\u2019re looking to host a frontend site or deploy a serverless function.","title":"Heroku vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#firebase-vs-vercel","text":"Firebase is a platform where you can host static sites as well as create and host serverless backend features for them whilst Vercel is a team oriented platform for frontend developers that allows them to integrate their changes and host the finished site and serverless functions on their infrastructure. Furthermore, firebase comes with two persistent ready to use databases (Realtime and Firestore) for your project whereas with Vercel you first have to connect to an external database, if you need one which might be in a different region than your app thereby introducing a latency risk. Consider using Firebase if you\u2019re not working as a team or need to get a database working for your project as fast as possible with no latency risk. It is worth noting that Vercel charges you per team member per month so consider Vercel if you\u2019re working as a team and don\u2019t have a tight budget.","title":"Firebase vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#github-pages-vs-vercel","text":"GitHub Pages is a free hosting solution for static sites using GitHub for version control while Vercel is a platform for hosting frontend sites from all the popular version control systems. In addition, Vercel also offers serverless backend services to its customers and has a pay as you grow model for the project you\u2019ll be hosting with them. Consider GitHub Pages if you\u2019re looking to deploy a static site for free or don\u2019t want to sign up for another service for your hosting needs as GitHub Pages uses your GitHub account to deploy the site. Consider Vercel if you\u2019re looking to deploy a site which doesn\u2019t use GitHub for version control or want to add serverless functions to your site.","title":"GitHub Pages vs Vercel"},{"location":"heroku-vs-netfliy-vs-vercel-vs-github-pages-vs-firebase-vs-vercel/#github-pages-vs-heroku","text":"GitHub Pages is a GitHub feature that allows you to freely serve static sites from GitHub repositories whilst Heroku is a cloud platform for hosting dynamic applications written in any of the popular backend programming languages like Ruby, Python, Java etc. Also, GitHub Pages only works with GitHub for version control whereas Heroku is flexible enough to work with all the major version control systems. Consider GitHub Pages if you want to host a static site for free and consider Heroku if you\u2019re looking to host a backend application or database.","title":"GitHub Pages vs Heroku"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/","text":"Kubernetes vs Docker vs OpenShift vs ECS vs Jenkins vs Terraform To better understand the differences between these services, let's first look at the difference between containerization and container orchestration . In short, containers contain code and the resources needed to run the code, while container orchestration is the automation of the management tasks of many containers (clusters). Containerization or containers are a method of building, packaging and deploying software. In essence, a container includes code and everything the code needs to run properly. A container is completely isolated and abstracts away the underlying infrastructure and operating system. Furthermore, it is a portable container that can be deployed on almost any infrastructure or public cloud service. Container orchestration is the automation of many of the underlying operational tasks required to run containerized workloads or services. This includes a wide range of tasks required to manage a container\u2019s lifecycle including provisioning, deployment, scaling, networking, load balancing and more. Kubernetes vs Docker Kubernetes is an open-source technology for orchestrating containers and deploying distributed applications, while Docker is an open-source technology for automating the deployment of applications as portable, self-sufficient containers that can run in the cloud or on-premises. In short, Docker is used to containerize applications and Kubernetes is used to manage clusters of containers. Docker can run on its own while Kubernetes needs a container runtime in order to orchestrate. Kubernetes is most commonly used with Docker but it can also be used with any container runtime. ie. RunC or cri-o . Although Kubernetes vs Docker is a common question these days, they are not directly comparable; in fact, they are complementary. While Docker provides an open standard for containerization of applications, Kubernetes provides the standardised means of orchestrating (managing) clusters of containers from a central platform. A more logical comparison would be Kubernetes vs Docker Swarm , Docker's native clustering solution. However, Kubernetes was designed to work well with Docker . Docker has since embraced Kubernetes and they are, in fact, offering their own integrated Kubernetes distribution in place of Docker Swarm as the default orchestration tool for Docker Enterprise. Consider Docker only, for smaller projects where the overhead of spinning up Kubernetes is unnecessary or unwanted. Consider Docker + Kubernetes for larger projects with multiple containers and where you need high-availability and efficient scaling. Kubernetes vs OpenShift Kubernetes and OpenShift are both container orchestration platforms or Container-as-a-Service (CaaS) providers. However, OpenShift offers a Platform-as-a-Service (PaaS) too, that utilizes Kubernetes to manage and run applications more efficiently. While OpenShift also has an open-source version, their core focus is to provide a commercial container management platform with added functionality such as stricter security policies, commercial support, networking and container image management. OpenShift is a RedHat Linux product and can only run on RedHat Atomic or Enterprise Linux (RHEL) for the commercial versions, and CentOS for the open-source version. On the contrary, Kubernetes is supported by most major cloud service providers like AWS, Azure, and Google Cloud Platform, and can run on any Linux distribution. Furthermore, even with Kubernetes ' large open-source community, deploying and managing Kubernetes is a very complex and resource-intensive undertaking while OpenShift provides an abstracted user interface where it is easier to visualise and manage application clusters and containers. Consider Kubernetes for high-demand applications if you have the resources to correctly manage it while taking advantage of their flexible deployment options. Consider OpenShift for a commercial, all-inclusive solution that offers constant and dedicated support. Kubernetes vs Amazon ECS and EKS Kubernetes and Amazon Elastic Container Service (ECS) are both highly scalable container management solutions. ECS is an Amazon Web Services (AWS) solution for managing containers and is tightly integrated with other AWS services like Route53, Elastic Load Balancer (ELB), Identity and Access Management (IAM) and many more. This makes it a little easier to add container orchestration to your solution, provided your whole solution runs on AWS. While Amazon ECS is an AWS opinionated container orchestration solution that only supports Docker containers on AWS, they also offer Amazon Elastic Kubernetes Service (EKS) which is Kubernetes on AWS. This allows you the flexibility to orchestrate clusters across many different cloud service providers and on-premises servers. Essentially, EKS is Kubernetes that runs on AWS infrastructure. Kubernetes brings more to the table than just container management. It provides a complete, managed execution environment for deploying, running, managing and orchestrating containers. While it also supports AWS, you have the added advantage of being able to move applications managed by Kubernetes to any other cloud service provider (GCP, Azure, etc.) or Linux distribution. Furthermore, Kubernetes is open-source and has a plug-in architecture that allows for many different open-source solutions to be added to its core functionality, such as OpenVSwitch for a network model and NFS for storage. It also boasts some unique features like shared secrets, config maps, auto-scaling and auto-healing of containers using cluster- and application-specific probes. A lot of the Kubernetes features can also be integrated with ECS , however, you'll have to combine quite a few AWS services like AWS Lambda to get the same features. Consider Kubernetes for a highly customisable and portable container solution that can be set up to meet all your needs. Keep in mind, though, that you'll have to build your solution yourself which means you need to have the necessary skills and resources. Consider Amazon ECS if you'll be running everything on AWS and you don't have the skills or resources to build your own Kubernetes solution. This also means you can take advantage of all the easily integrated services that AWS offers. Consider Amazon EKS for a hybrid solution that integrates easily with other AWS services but allows you the flexibility of also orchestrating containers across other cloud platforms and on-premises infrastructure. Kubernetes vs Jenkins Kubernetes is a complete, managed execution environment for deploying, running, managing and orchestrating containers while Jenkins is an open-source continuous integration and deployment (CI/CD) server that enforces automation in building, testing and deployment of applications. Kubernetes and Jenkins are mostly used in unison where Kubernetes takes care of the container management and orchestration, while Jenkins ensures continuous integration and deployment through automating the building, testing and deployment pipelines. In this case, it's not a question of either/or but rather using a combination of the two for an automated and efficient software release cycle that follows modern Agile methodologies. Kubernetes vs Terraform Kubernetes is a container orchestration platform that allows developers to manage clusters of containers like Docker containers, while Terraform is an open-source infrastructure-as-code software tool that provides developers with a consistent CLI workflow to manage hundreds of cloud services. Terraform allows developers to manage, deploy and orchestrate infrastructure as code. This means they codify cloud APIs into declarative configuration files that enable developers to manage infrastructure with human-readable code. Furthermore, this allows for any output generated by the infrastructure to be used as input to configure other infrastructure including Kubernetes clusters. Terraform integrates seamlessly into any cloud service provider including each of their own Kubernetes solutions. For this reason, Kubernetes and Terraform are often used in unison. However, Terraform can be used to manage almost any cloud infrastructure and Kubernetes can be used on its own to manage any containerized infrastructure like Docker containers. Consider Kubernetes if your infrastructure solely consists of containers and you have the resources to build and maintain your own container orchestration solution. Consider Terraform if your infrastructure consists of a combination of many different types of infrastructure, including Kubernetes , from different providers. This will allow you to easily manage and automate most of your infrastructure with human-readable code. Docker vs OpenShift Docker is an open-source technology for automating the deployment of applications as portable, self-sufficient containers that can run in the cloud or on-premises. OpenShift is a PaaS that allows developers to deploy and scale applications easily through their platform which also makes use of container orchestration technology, Kubernetes, to manage Docker containers. While both technologies use the same underlying container technology, Docker is simply the container technology itself. OpenShift , on the other hand, adds abstracted container cluster orchestration, management and some other features to form a whole software development and deployment solution. Consider Docker alone for smaller projects and prototyping where there is no need to rapidly scale. Consider OpenShift for a complete container management platform that offers many additional services including dedicated support. As an example of how many of these technologies can work together let's consider the following: You can use Terraform to manage all of your infrastructure which includes Kubernetes . Kubernetes will handle the container orchestration and receive its instructions from Terraform . Our services are all contained in Docker containers which are managed automatically by Kubernetes . Furthermore, we can integrate Terraform with Jenkins to add CI/CD workflows and automation. This is just a simple example of how these technologies and services complement each other. There are multiple ways of building a development and deployment pipeline and most cloud providers each provide their own combinations and services specially designed for this.","title":"Kubernetes vs Docker vs OpenShift vs ECS vs Jenkins vs Terraform"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform","text":"To better understand the differences between these services, let's first look at the difference between containerization and container orchestration . In short, containers contain code and the resources needed to run the code, while container orchestration is the automation of the management tasks of many containers (clusters). Containerization or containers are a method of building, packaging and deploying software. In essence, a container includes code and everything the code needs to run properly. A container is completely isolated and abstracts away the underlying infrastructure and operating system. Furthermore, it is a portable container that can be deployed on almost any infrastructure or public cloud service. Container orchestration is the automation of many of the underlying operational tasks required to run containerized workloads or services. This includes a wide range of tasks required to manage a container\u2019s lifecycle including provisioning, deployment, scaling, networking, load balancing and more.","title":"Kubernetes vs Docker vs OpenShift vs ECS vs Jenkins vs Terraform"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-docker","text":"Kubernetes is an open-source technology for orchestrating containers and deploying distributed applications, while Docker is an open-source technology for automating the deployment of applications as portable, self-sufficient containers that can run in the cloud or on-premises. In short, Docker is used to containerize applications and Kubernetes is used to manage clusters of containers. Docker can run on its own while Kubernetes needs a container runtime in order to orchestrate. Kubernetes is most commonly used with Docker but it can also be used with any container runtime. ie. RunC or cri-o . Although Kubernetes vs Docker is a common question these days, they are not directly comparable; in fact, they are complementary. While Docker provides an open standard for containerization of applications, Kubernetes provides the standardised means of orchestrating (managing) clusters of containers from a central platform. A more logical comparison would be Kubernetes vs Docker Swarm , Docker's native clustering solution. However, Kubernetes was designed to work well with Docker . Docker has since embraced Kubernetes and they are, in fact, offering their own integrated Kubernetes distribution in place of Docker Swarm as the default orchestration tool for Docker Enterprise. Consider Docker only, for smaller projects where the overhead of spinning up Kubernetes is unnecessary or unwanted. Consider Docker + Kubernetes for larger projects with multiple containers and where you need high-availability and efficient scaling.","title":"Kubernetes vs Docker"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-openshift","text":"Kubernetes and OpenShift are both container orchestration platforms or Container-as-a-Service (CaaS) providers. However, OpenShift offers a Platform-as-a-Service (PaaS) too, that utilizes Kubernetes to manage and run applications more efficiently. While OpenShift also has an open-source version, their core focus is to provide a commercial container management platform with added functionality such as stricter security policies, commercial support, networking and container image management. OpenShift is a RedHat Linux product and can only run on RedHat Atomic or Enterprise Linux (RHEL) for the commercial versions, and CentOS for the open-source version. On the contrary, Kubernetes is supported by most major cloud service providers like AWS, Azure, and Google Cloud Platform, and can run on any Linux distribution. Furthermore, even with Kubernetes ' large open-source community, deploying and managing Kubernetes is a very complex and resource-intensive undertaking while OpenShift provides an abstracted user interface where it is easier to visualise and manage application clusters and containers. Consider Kubernetes for high-demand applications if you have the resources to correctly manage it while taking advantage of their flexible deployment options. Consider OpenShift for a commercial, all-inclusive solution that offers constant and dedicated support.","title":"Kubernetes vs OpenShift"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-amazon-ecs-and-eks","text":"Kubernetes and Amazon Elastic Container Service (ECS) are both highly scalable container management solutions. ECS is an Amazon Web Services (AWS) solution for managing containers and is tightly integrated with other AWS services like Route53, Elastic Load Balancer (ELB), Identity and Access Management (IAM) and many more. This makes it a little easier to add container orchestration to your solution, provided your whole solution runs on AWS. While Amazon ECS is an AWS opinionated container orchestration solution that only supports Docker containers on AWS, they also offer Amazon Elastic Kubernetes Service (EKS) which is Kubernetes on AWS. This allows you the flexibility to orchestrate clusters across many different cloud service providers and on-premises servers. Essentially, EKS is Kubernetes that runs on AWS infrastructure. Kubernetes brings more to the table than just container management. It provides a complete, managed execution environment for deploying, running, managing and orchestrating containers. While it also supports AWS, you have the added advantage of being able to move applications managed by Kubernetes to any other cloud service provider (GCP, Azure, etc.) or Linux distribution. Furthermore, Kubernetes is open-source and has a plug-in architecture that allows for many different open-source solutions to be added to its core functionality, such as OpenVSwitch for a network model and NFS for storage. It also boasts some unique features like shared secrets, config maps, auto-scaling and auto-healing of containers using cluster- and application-specific probes. A lot of the Kubernetes features can also be integrated with ECS , however, you'll have to combine quite a few AWS services like AWS Lambda to get the same features. Consider Kubernetes for a highly customisable and portable container solution that can be set up to meet all your needs. Keep in mind, though, that you'll have to build your solution yourself which means you need to have the necessary skills and resources. Consider Amazon ECS if you'll be running everything on AWS and you don't have the skills or resources to build your own Kubernetes solution. This also means you can take advantage of all the easily integrated services that AWS offers. Consider Amazon EKS for a hybrid solution that integrates easily with other AWS services but allows you the flexibility of also orchestrating containers across other cloud platforms and on-premises infrastructure.","title":"Kubernetes vs Amazon ECS and EKS"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-jenkins","text":"Kubernetes is a complete, managed execution environment for deploying, running, managing and orchestrating containers while Jenkins is an open-source continuous integration and deployment (CI/CD) server that enforces automation in building, testing and deployment of applications. Kubernetes and Jenkins are mostly used in unison where Kubernetes takes care of the container management and orchestration, while Jenkins ensures continuous integration and deployment through automating the building, testing and deployment pipelines. In this case, it's not a question of either/or but rather using a combination of the two for an automated and efficient software release cycle that follows modern Agile methodologies.","title":"Kubernetes vs Jenkins"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#kubernetes-vs-terraform","text":"Kubernetes is a container orchestration platform that allows developers to manage clusters of containers like Docker containers, while Terraform is an open-source infrastructure-as-code software tool that provides developers with a consistent CLI workflow to manage hundreds of cloud services. Terraform allows developers to manage, deploy and orchestrate infrastructure as code. This means they codify cloud APIs into declarative configuration files that enable developers to manage infrastructure with human-readable code. Furthermore, this allows for any output generated by the infrastructure to be used as input to configure other infrastructure including Kubernetes clusters. Terraform integrates seamlessly into any cloud service provider including each of their own Kubernetes solutions. For this reason, Kubernetes and Terraform are often used in unison. However, Terraform can be used to manage almost any cloud infrastructure and Kubernetes can be used on its own to manage any containerized infrastructure like Docker containers. Consider Kubernetes if your infrastructure solely consists of containers and you have the resources to build and maintain your own container orchestration solution. Consider Terraform if your infrastructure consists of a combination of many different types of infrastructure, including Kubernetes , from different providers. This will allow you to easily manage and automate most of your infrastructure with human-readable code.","title":"Kubernetes vs Terraform"},{"location":"kubernetes-vs-docker-vs-openshift-vs-ecs-vs-jenkins-vs-terraform/#docker-vs-openshift","text":"Docker is an open-source technology for automating the deployment of applications as portable, self-sufficient containers that can run in the cloud or on-premises. OpenShift is a PaaS that allows developers to deploy and scale applications easily through their platform which also makes use of container orchestration technology, Kubernetes, to manage Docker containers. While both technologies use the same underlying container technology, Docker is simply the container technology itself. OpenShift , on the other hand, adds abstracted container cluster orchestration, management and some other features to form a whole software development and deployment solution. Consider Docker alone for smaller projects and prototyping where there is no need to rapidly scale. Consider OpenShift for a complete container management platform that offers many additional services including dedicated support. As an example of how many of these technologies can work together let's consider the following: You can use Terraform to manage all of your infrastructure which includes Kubernetes . Kubernetes will handle the container orchestration and receive its instructions from Terraform . Our services are all contained in Docker containers which are managed automatically by Kubernetes . Furthermore, we can integrate Terraform with Jenkins to add CI/CD workflows and automation. This is just a simple example of how these technologies and services complement each other. There are multiple ways of building a development and deployment pipeline and most cloud providers each provide their own combinations and services specially designed for this.","title":"Docker vs OpenShift"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/","text":"Learning Piano vs Learning Guitar vs Learning Keyboard vs Learning Violin vs Learning Cello Learning Piano vs Learning Guitar At first, learning to play the piano is a little easier than learning the guitar. With a piano, a beginner can simply start playing by pressing the keys, while with a guitar you'll need some practice to get your fingers and hands strong enough to play the notes correctly. Also, your fretting hand's fingertips need to develop calluses in order to play guitar without hurting your fingers. On a piano, all the notes are laid out sequentially and each note can only be played on one specific key. The keys are also coloured black or white, which makes it easy to see how the notes are laid out in relation to one another. Intervals are also clearly visible. On a guitar, the notes are laid out differently to accommodate for different hand positions. This allows players to play the same note in many different places, which makes it a bit harder to grasp musical theory with a guitar. Reading music is also much simpler with a piano as the written music (bass and treble clef) is easily translated to the piano (left and right hand) while with a guitar, the music is written slightly differently to accommodate the tuning of the strings. Pianos are set up and tuned by a professional once, and only need to be tuned again when it is moved or for occasional routine maintenance. Guitars need to be tuned every time they are played. For beginners, this also makes the piano a better choice as you can first learn the basics and properly train your ear without the need to worry about tuning. Incorrectly tuning your guitar might make it difficult to properly train your ears as you might not tune your guitar correctly all the time. Budget and portability are also huge considerations here, as a piano is far more expensive than a guitar and is generally a \"fixed\" instrument, meaning it is set up in one place and rarely moved ie. in a Church. Guitars, on the other hand, range from cheap beginner guitars all the way to guitars that cost as much as a grand piano. This allows for a more flexible budget when buying your first guitar. Guitars are also portable and great for performing musicians as they can perform on the same instrument that they practiced with, which isn't the case for pianos \u2013 unless you are Alecia Keys, who travels around the world with her grand piano. When choosing between the two instruments, it comes down to personal preference and the type of music you would like to play. If you're still undecided... Consider learning piano if you have access to one and you are keen to develop a better music theory foundation for yourself. With good music-theoretical knowledge and a developed musical ear, you can carry over your skills to other instruments more easily later on. Also, if delayed gratification is a problem for you, the piano is a much better choice as you can play satisfying music much quicker. Consider learning guitar if you want to play an instrument that is affordable and you plan on performing/practicing in different locations. Guitar is a good choice if you're up for a slightly steeper learning curve in the beginning and have the patience and persistence to keep practicing until you develop the strength in your hands to play the chords and notes correctly. Learning Piano vs Learning Keyboard A piano is a large acoustic instrument that houses a soundboard and strings which are struck by wooden hammers when a key is pressed. The vibration of the strings is muted when a key is released and can be controlled for volume and length by two or three pedals. A standard piano has 88 weighted keys that give the player more control over tone and volume. Pianos are generally \"fixed\" instruments, meaning you permanently set it up in a single location where it will be played ie. in a Church. They are simply too large and heavy to be considered mobile and they need to be tuned by a professional every time they are moved. A keyboard is an electric instrument that resembles a piano but comes in various types and sizes. With a keyboard's lighter keys, the player does not have the same feel and control over the tone. However, modern keyboards today have many sounds and features that allow the player more variety in the types of music they can produce. Most keyboards today come with hundreds of sounds, backing tracks, metronomes and more, allowing for more options when it comes to producing modern music. Keyboards are great for performing musicians as they are easy to transport and set up at different locations. This also allows musicians to perform on the same instrument that they practiced on. For a beginner, it can be more satisfying to play the piano because you can produce a satisfying sound from the harmonics of the surrounding strings after hitting one note. A piano also has a better \"feel\" with the weighted keys. However, some keyboards also have weighted keys but these are more accurately called \"digital pianos\" which give the player the same \"feel\" on the keys but don't produce the same harmonics. Pianos are much more expensive than digital pianos and keyboards, so if you aren't committed to practicing the piano for a long time, you might consider starting off with a more affordable keyboard until you become good enough to take full advantage of the beautiful tone and feel that a piano has to offer. If you are still undecided... Consider learning piano if you can afford access to one and you prefer to play with the weighted keys and uniquely beautiful sound it produces. Consider learning keyboard or digital piano if you'll be playing at different locations and if you want to especially make use of all the extra sounds and features modern keyboards offer. Learning Piano vs Learning Violin Pianos and violins are both hard instruments to master but when it comes to perfect tone, violins are much harder. For a beginner, it's a little easier to get started with a piano; with a violin, you'll have to develop muscle memory to accurately press the notes. A violin is a stringed acoustic instrument much like a small guitar or ukulele but has no frets and is played by sliding a bow over the strings instead of plucking them. With no frets, it is especially difficult to get exactly the note you are looking for as your finger placement needs to be precise, without any visible indication as to where you must place your finger. This means that violins require a trained ear, apart from tuning the strings a violin player actually tunes each note as they play. On a piano, the keys are laid out sequentially so it's easier to learn where all the notes are and much easier to produce a nice sound, as a beginner. With a piano, a beginner can quickly learn how to play a simple song which helps keep them motivated to continue practicing. With a violin, it can become discouraging when you've practiced a lot and still can't produce a satisfying sound. These are two very different instruments both in the way they are played and in the sound they produce. So again, the choice is based on what music you want to play. However, if you are still undecided... Consider learning piano if you want to learn music theory and be able to play satisfying songs quicker. Consider learning violin if you don't mind the steeper learning curve and won't get discouraged by practicing long hours with little progress at first. Learning Piano vs Learning Cello Piano and cello are both difficult to master but the piano is easier to get started with and will give you more satisfying results quicker. Also, the skill learned on a piano is more easily transferable to other instruments later on. A cello is a bowed string instrument of the violin family that is mostly used to play bass. It is the second largest of the violin family, played upright with the base resting on the floor between the player\u2019s knees. With piano, you'll be able to play a simple song like \"Twinkle, Twinkle Little Star\" within a couple of hours, whereas with a cello you'll need a fair amount of practice just to correctly draw the bow over the strings to produce a decent sound. Also, because a cello is a fretless instrument, it will take a fair amount of practice to put your fingers in the right spot to play the notes in tune. A piano allows the player to play a complete composition including bass, rhythm and melody. With a cello or violin, the player is limited to play only one of them at a time which can make solo playing less fun. There are a lot of resources available to learn and practice piano on your own. A cello is a much harder instrument to learn without a teacher. These instruments each fall into their own categories and produce different sounds, so making your choice based on what music you want to play should be easy. If you are still undecided... Consider learning piano if you want to learn music theory faster and you have access to a piano. Pianos are also great if you want to play a larger variety of music. Consider learning cello if you like a deeper sound, prefer a stringed bow instrument and you have access to a skilled cello teacher. Learning Guitar vs Learning Violin A guitar and a violin are both stringed instruments but fall under different categories, where a guitar's strings are plucked with your finger or a plectrum, a violin\u2019s sound is produced by drawing a bow across the strings. Furthermore, a guitar is a fretted instrument meaning it has thin metal strips placed along the neck to ensure a specific tone is produced when you press your finger between two frets. A violin has no frets meaning no guidance on finger placement when trying to produce a specific sound. If finger placement is even slightly off, the sound will be off too. A violin helps musicians develop a more in-tune musical ear, as the player relies more on the sound of the note than on a visual indicator. However, in the beginning, it can be frustrating as it can take a long time and a lot of dedication to get to a point where you'll be able to get a satisfying sound out of your instrument. A violin is considered to be one of the hardest instruments to learn compared to other stringed instruments. A beginner guitar player will play better guitar in a month than a violinist will play violin in the same amount of time. When played correctly, violins have a beautiful sound, more unique compared to most other instruments. The learning curve is much steeper with a violin than with a guitar, especially in the beginning, but produces a much smoother sound in the end. This means if you are dedicated and committed to practicing for a long time, honing your skills, you will be able to produce much nicer compositions from a violin than that of a guitar. Guitars have thicker strings and will hurt your fingers until you develop calluses. With a violin, the strings are much thinner and easier to press down, however without frets the slightest movement will change the pitch so your hands would still need to develop the strength to keep your finger in the correct place to produce exactly the sound you want. Guitars are better for multitasking ie. singing while playing. This is much harder(almost impossible) to do the same with a violin, as the instrument is held under the chin. If you are undecided... Consider learning guitar for a slightly flatter learning curve and if you plan on singing while playing. Also to take advantage of the ample online guitar learning resources for self-study. Consider learning violin if you prefer a bowed instrument and don't mind putting in a little more effort and practice with a skilled teacher. Learning Guitar vs Learning Keyboard The guitar has a slightly steeper learning curve in the beginning compared to a keyboard, but both are equally difficult to master. While keyboards require finger dexterity and rhythm, they don't require the same strength and calluses that guitar playing demands. This makes it a little easier and more satisfying for a complete beginner to learn the keyboard, as they would be able to produce some nice sounding chords quicker, without the need to go through the painful part of developing calluses. A keyboard lays out all of the notes in a linear fashion, and colour codes your sharps and flats, making it easier to visualise and remember them. A guitar's notes are laid out linearly on each string but each string starts on a different note, making it more difficult to visualise and learn the notes of the stacked strings. The keyboard also makes music theory, chords, scales and sight reading easier because of the above. With a guitar, written music looks a little different to accommodate for the tuning of the guitar, where with a keyboard it is easier to read the bass and treble clef as they correspond with your left and right hand. Consider learning guitar if you prefer stringed instruments and don't mind the steeper learning curve and painful fingers in the beginning. Consider learning keyboard if you want to learn music theory quicker and be able to produce many different sounds from the same instrument. Learning Cello vs Learning Violin Cellos and violins are both stringed bowed instruments but cellos are larger and tuned to play lower bass notes while violins are much smaller and tuned to play higher melodic notes. A cello is placed upright on the floor with the base of the cello between the player\u2019s knees while a violin is held between one hand and the player\u2019s neck. Cello is considered easier to learn because of its more natural position while playing. However, many violin players say that after a while of playing, the position a violin is held becomes natural, too. Consider learning cello if you prefer the low-frequency sound it produces and if you have the budget to afford one. Also, if you prefer the position it is held when played and don't mind travelling with a much larger instrument. Consider violin if you prefer a smaller and much more portable instrument with an affordable price tag and a higher-frequency sound. Learning Cello vs Learning Guitar Cello is more difficult than guitar because it has no frets, similar to a violin. Getting the intonation right on a cello is much harder than with a guitar, so you'll definitely need a teacher to help you. With a guitar, it is possible to follow online course videos to get the same or similar results you\u2019d get from a teacher. Even though a guitar can get you playing more quickly, the skills developed with a cello will make you a much better musician in the long run. Cello skills are more easily transferred to other instruments, especially bow instruments. With a guitar, it is easier to accompany yourself with chords while a cello is not really designed for chords and is mostly played as an accompanying instrument with orchestras and bands. A guitar offers more variety to play different types and genres of music while a cello produces a very unique deep sound. Your choice will depend a lot on the type and genre of music you would like to play, as each instrument falls into a category of their own. If you are still undecided... Consider learning cello if you can afford a cello along with a skilled teacher. Also, cello is great if you want to develop a more accurate musical ear. Consider learning guitar if you want to play a variety of genres and plan to sing along.","title":"Learning Piano vs Learning Guitar vs Learning Keyboard vs Learning Violin vs Learning Cello"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello","text":"","title":"Learning Piano vs Learning Guitar vs Learning Keyboard vs Learning Violin vs Learning Cello"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-piano-vs-learning-guitar","text":"At first, learning to play the piano is a little easier than learning the guitar. With a piano, a beginner can simply start playing by pressing the keys, while with a guitar you'll need some practice to get your fingers and hands strong enough to play the notes correctly. Also, your fretting hand's fingertips need to develop calluses in order to play guitar without hurting your fingers. On a piano, all the notes are laid out sequentially and each note can only be played on one specific key. The keys are also coloured black or white, which makes it easy to see how the notes are laid out in relation to one another. Intervals are also clearly visible. On a guitar, the notes are laid out differently to accommodate for different hand positions. This allows players to play the same note in many different places, which makes it a bit harder to grasp musical theory with a guitar. Reading music is also much simpler with a piano as the written music (bass and treble clef) is easily translated to the piano (left and right hand) while with a guitar, the music is written slightly differently to accommodate the tuning of the strings. Pianos are set up and tuned by a professional once, and only need to be tuned again when it is moved or for occasional routine maintenance. Guitars need to be tuned every time they are played. For beginners, this also makes the piano a better choice as you can first learn the basics and properly train your ear without the need to worry about tuning. Incorrectly tuning your guitar might make it difficult to properly train your ears as you might not tune your guitar correctly all the time. Budget and portability are also huge considerations here, as a piano is far more expensive than a guitar and is generally a \"fixed\" instrument, meaning it is set up in one place and rarely moved ie. in a Church. Guitars, on the other hand, range from cheap beginner guitars all the way to guitars that cost as much as a grand piano. This allows for a more flexible budget when buying your first guitar. Guitars are also portable and great for performing musicians as they can perform on the same instrument that they practiced with, which isn't the case for pianos \u2013 unless you are Alecia Keys, who travels around the world with her grand piano. When choosing between the two instruments, it comes down to personal preference and the type of music you would like to play. If you're still undecided... Consider learning piano if you have access to one and you are keen to develop a better music theory foundation for yourself. With good music-theoretical knowledge and a developed musical ear, you can carry over your skills to other instruments more easily later on. Also, if delayed gratification is a problem for you, the piano is a much better choice as you can play satisfying music much quicker. Consider learning guitar if you want to play an instrument that is affordable and you plan on performing/practicing in different locations. Guitar is a good choice if you're up for a slightly steeper learning curve in the beginning and have the patience and persistence to keep practicing until you develop the strength in your hands to play the chords and notes correctly.","title":"Learning Piano vs Learning Guitar"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-piano-vs-learning-keyboard","text":"A piano is a large acoustic instrument that houses a soundboard and strings which are struck by wooden hammers when a key is pressed. The vibration of the strings is muted when a key is released and can be controlled for volume and length by two or three pedals. A standard piano has 88 weighted keys that give the player more control over tone and volume. Pianos are generally \"fixed\" instruments, meaning you permanently set it up in a single location where it will be played ie. in a Church. They are simply too large and heavy to be considered mobile and they need to be tuned by a professional every time they are moved. A keyboard is an electric instrument that resembles a piano but comes in various types and sizes. With a keyboard's lighter keys, the player does not have the same feel and control over the tone. However, modern keyboards today have many sounds and features that allow the player more variety in the types of music they can produce. Most keyboards today come with hundreds of sounds, backing tracks, metronomes and more, allowing for more options when it comes to producing modern music. Keyboards are great for performing musicians as they are easy to transport and set up at different locations. This also allows musicians to perform on the same instrument that they practiced on. For a beginner, it can be more satisfying to play the piano because you can produce a satisfying sound from the harmonics of the surrounding strings after hitting one note. A piano also has a better \"feel\" with the weighted keys. However, some keyboards also have weighted keys but these are more accurately called \"digital pianos\" which give the player the same \"feel\" on the keys but don't produce the same harmonics. Pianos are much more expensive than digital pianos and keyboards, so if you aren't committed to practicing the piano for a long time, you might consider starting off with a more affordable keyboard until you become good enough to take full advantage of the beautiful tone and feel that a piano has to offer. If you are still undecided... Consider learning piano if you can afford access to one and you prefer to play with the weighted keys and uniquely beautiful sound it produces. Consider learning keyboard or digital piano if you'll be playing at different locations and if you want to especially make use of all the extra sounds and features modern keyboards offer.","title":"Learning Piano vs Learning Keyboard"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-piano-vs-learning-violin","text":"Pianos and violins are both hard instruments to master but when it comes to perfect tone, violins are much harder. For a beginner, it's a little easier to get started with a piano; with a violin, you'll have to develop muscle memory to accurately press the notes. A violin is a stringed acoustic instrument much like a small guitar or ukulele but has no frets and is played by sliding a bow over the strings instead of plucking them. With no frets, it is especially difficult to get exactly the note you are looking for as your finger placement needs to be precise, without any visible indication as to where you must place your finger. This means that violins require a trained ear, apart from tuning the strings a violin player actually tunes each note as they play. On a piano, the keys are laid out sequentially so it's easier to learn where all the notes are and much easier to produce a nice sound, as a beginner. With a piano, a beginner can quickly learn how to play a simple song which helps keep them motivated to continue practicing. With a violin, it can become discouraging when you've practiced a lot and still can't produce a satisfying sound. These are two very different instruments both in the way they are played and in the sound they produce. So again, the choice is based on what music you want to play. However, if you are still undecided... Consider learning piano if you want to learn music theory and be able to play satisfying songs quicker. Consider learning violin if you don't mind the steeper learning curve and won't get discouraged by practicing long hours with little progress at first.","title":"Learning Piano vs Learning Violin"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-piano-vs-learning-cello","text":"Piano and cello are both difficult to master but the piano is easier to get started with and will give you more satisfying results quicker. Also, the skill learned on a piano is more easily transferable to other instruments later on. A cello is a bowed string instrument of the violin family that is mostly used to play bass. It is the second largest of the violin family, played upright with the base resting on the floor between the player\u2019s knees. With piano, you'll be able to play a simple song like \"Twinkle, Twinkle Little Star\" within a couple of hours, whereas with a cello you'll need a fair amount of practice just to correctly draw the bow over the strings to produce a decent sound. Also, because a cello is a fretless instrument, it will take a fair amount of practice to put your fingers in the right spot to play the notes in tune. A piano allows the player to play a complete composition including bass, rhythm and melody. With a cello or violin, the player is limited to play only one of them at a time which can make solo playing less fun. There are a lot of resources available to learn and practice piano on your own. A cello is a much harder instrument to learn without a teacher. These instruments each fall into their own categories and produce different sounds, so making your choice based on what music you want to play should be easy. If you are still undecided... Consider learning piano if you want to learn music theory faster and you have access to a piano. Pianos are also great if you want to play a larger variety of music. Consider learning cello if you like a deeper sound, prefer a stringed bow instrument and you have access to a skilled cello teacher.","title":"Learning Piano vs Learning Cello"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-guitar-vs-learning-violin","text":"A guitar and a violin are both stringed instruments but fall under different categories, where a guitar's strings are plucked with your finger or a plectrum, a violin\u2019s sound is produced by drawing a bow across the strings. Furthermore, a guitar is a fretted instrument meaning it has thin metal strips placed along the neck to ensure a specific tone is produced when you press your finger between two frets. A violin has no frets meaning no guidance on finger placement when trying to produce a specific sound. If finger placement is even slightly off, the sound will be off too. A violin helps musicians develop a more in-tune musical ear, as the player relies more on the sound of the note than on a visual indicator. However, in the beginning, it can be frustrating as it can take a long time and a lot of dedication to get to a point where you'll be able to get a satisfying sound out of your instrument. A violin is considered to be one of the hardest instruments to learn compared to other stringed instruments. A beginner guitar player will play better guitar in a month than a violinist will play violin in the same amount of time. When played correctly, violins have a beautiful sound, more unique compared to most other instruments. The learning curve is much steeper with a violin than with a guitar, especially in the beginning, but produces a much smoother sound in the end. This means if you are dedicated and committed to practicing for a long time, honing your skills, you will be able to produce much nicer compositions from a violin than that of a guitar. Guitars have thicker strings and will hurt your fingers until you develop calluses. With a violin, the strings are much thinner and easier to press down, however without frets the slightest movement will change the pitch so your hands would still need to develop the strength to keep your finger in the correct place to produce exactly the sound you want. Guitars are better for multitasking ie. singing while playing. This is much harder(almost impossible) to do the same with a violin, as the instrument is held under the chin. If you are undecided... Consider learning guitar for a slightly flatter learning curve and if you plan on singing while playing. Also to take advantage of the ample online guitar learning resources for self-study. Consider learning violin if you prefer a bowed instrument and don't mind putting in a little more effort and practice with a skilled teacher.","title":"Learning Guitar vs Learning Violin"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-guitar-vs-learning-keyboard","text":"The guitar has a slightly steeper learning curve in the beginning compared to a keyboard, but both are equally difficult to master. While keyboards require finger dexterity and rhythm, they don't require the same strength and calluses that guitar playing demands. This makes it a little easier and more satisfying for a complete beginner to learn the keyboard, as they would be able to produce some nice sounding chords quicker, without the need to go through the painful part of developing calluses. A keyboard lays out all of the notes in a linear fashion, and colour codes your sharps and flats, making it easier to visualise and remember them. A guitar's notes are laid out linearly on each string but each string starts on a different note, making it more difficult to visualise and learn the notes of the stacked strings. The keyboard also makes music theory, chords, scales and sight reading easier because of the above. With a guitar, written music looks a little different to accommodate for the tuning of the guitar, where with a keyboard it is easier to read the bass and treble clef as they correspond with your left and right hand. Consider learning guitar if you prefer stringed instruments and don't mind the steeper learning curve and painful fingers in the beginning. Consider learning keyboard if you want to learn music theory quicker and be able to produce many different sounds from the same instrument.","title":"Learning Guitar vs Learning Keyboard"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-cello-vs-learning-violin","text":"Cellos and violins are both stringed bowed instruments but cellos are larger and tuned to play lower bass notes while violins are much smaller and tuned to play higher melodic notes. A cello is placed upright on the floor with the base of the cello between the player\u2019s knees while a violin is held between one hand and the player\u2019s neck. Cello is considered easier to learn because of its more natural position while playing. However, many violin players say that after a while of playing, the position a violin is held becomes natural, too. Consider learning cello if you prefer the low-frequency sound it produces and if you have the budget to afford one. Also, if you prefer the position it is held when played and don't mind travelling with a much larger instrument. Consider violin if you prefer a smaller and much more portable instrument with an affordable price tag and a higher-frequency sound.","title":"Learning Cello vs Learning Violin"},{"location":"learning-piano-vs-learning-guitar-vs-learning-keyboard-vs-learning-violin-vs-learning-cello/#learning-cello-vs-learning-guitar","text":"Cello is more difficult than guitar because it has no frets, similar to a violin. Getting the intonation right on a cello is much harder than with a guitar, so you'll definitely need a teacher to help you. With a guitar, it is possible to follow online course videos to get the same or similar results you\u2019d get from a teacher. Even though a guitar can get you playing more quickly, the skills developed with a cello will make you a much better musician in the long run. Cello skills are more easily transferred to other instruments, especially bow instruments. With a guitar, it is easier to accompany yourself with chords while a cello is not really designed for chords and is mostly played as an accompanying instrument with orchestras and bands. A guitar offers more variety to play different types and genres of music while a cello produces a very unique deep sound. Your choice will depend a lot on the type and genre of music you would like to play, as each instrument falls into a category of their own. If you are still undecided... Consider learning cello if you can afford a cello along with a skilled teacher. Also, cello is great if you want to develop a more accurate musical ear. Consider learning guitar if you want to play a variety of genres and plan to sing along.","title":"Learning Cello vs Learning Guitar"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/","text":"OpenGrok vs Sourcegraph vs GitHub vs FishEye vs Source Insight vs Elasticsearch OpenGrok vs Sourcegraph OpenGrok and Sourcegraph are both open-source code search and navigation tools. OpenGrok is one of the pioneers in code-search and navigation tools and was developed by Sun Microsystems back in 2004. OpenGrok has become an Oracle open-source project since Oracle acquired Sun. OpenGrok is written in Java and is still actively maintained. Sourcegraph has a more comprehensive feature offering with a more modern and user-friendly interface. With Sourcegraph, you can search entire codebases across multiple code hosts. The tool came along in 2017 and is gradually becoming the \"go-to\" tool when it comes to code search. Sourcegraph has overtaken OpenGrok in popularity amongst developers when comparing Google trends and GitHub activity and stars. Consider OpenGrok if it's already the tool your company/peers use for code search and navigation. Consider SourceGraph if you are looking for a modern, well maintained and comprehensive code search and intelligence tool. OpenGrok vs GitHub GitHub is a code hosting platform with version control (Git) and collaboration features while OpenGrok is a code search and cross-referencing engine. Consider GitHub for hosting your code to make use of their version control and collaboration features. Consider OpenGrok if you need to add the power of code search and cross-referencing on top of your version control service/platform, ie. integrating OpenGrok with your GitHub repositories. OpenGrok vs Fisheye Fisheye is a commercial revision-control browser and search engine owned by Atlassian Inc. It is freely available to open-source projects and non-profits. With Fisheye, developers can search code, visualize and report on activity, and search through commits, files, revisions or teammates across SVN, Git, Mercurial, CVS and Perforce. While OpenGrok is a similar code search and cross-referencing engine, it has superior code search capabilities and supports multiple version control systems. However, OpenGrok falls short on a few key features like visual reports on activity. Consider Fisheye if your team uses Jira for easy integration and collaboration, or if you have a need for the reporting features that Fisheye provides. Consider OpenGrok if you are already accustomed to the OpenGrok workflow or if you use a version control system that is not supported by Fisheye. OpenGrok vs Source Insight OpenGrok is a fast source code search and cross-reference engine while Source Insight is a programming editor, code browser and analyzer that helps developers understand code. Source Insight provides syntax highlighting, code navigation and customizable keyboard shortcuts. It goes beyond editing functionality and is a tool to understand a large source codebase. For this reason, it\u2019s called a \"program editor and analyzer\u201d. Consider OpenGrok if you are simply looking for a code search and cross-referencing engine to bolt on top of your existing workflow. Consider Source Insight if you are looking for an all-in-one programming tool that includes code search and collaboration features along with code analysis. OpenGrok vs Elasticsearch OpenGrok is a universal code search and navigation tool for developers. OpenGrok is a stand-alone tool with its own search engine. Elasticsearch is a low-level search engine that other applications can use to provide search functionality. Elasticsearch is not an end-user product, it's just a search engine that provides low-level indexing and query APIs to your own applications, but you need to build the UI, syncing, analysis, deployment, etc. yourself. Consider Elasticsearch if you plan to build your own application with strong search capabilities. Consider OpenGrok if you are looking for a stand-alone code search and navigation tool. GitHub vs Sourcegraph GitHub is a code host with version control functionality using Git. Sourcegraph is a web-based code search and navigation tool for developers. Sourcegraph's superior search functionality can easily be added on top of GitHub with Sourcegraph integration for larger organizations. Consider GitHub alone if you work in a small organization where GitHub's search functionality covers your needs. Consider Sourcegraph if you work in a larger organization and need more powerful search and collaboration functionality.","title":"OpenGrok vs Sourcegraph vs GitHub vs FishEye vs Source Insight vs Elasticsearch"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch","text":"","title":"OpenGrok vs Sourcegraph vs GitHub vs FishEye vs Source Insight vs Elasticsearch"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-sourcegraph","text":"OpenGrok and Sourcegraph are both open-source code search and navigation tools. OpenGrok is one of the pioneers in code-search and navigation tools and was developed by Sun Microsystems back in 2004. OpenGrok has become an Oracle open-source project since Oracle acquired Sun. OpenGrok is written in Java and is still actively maintained. Sourcegraph has a more comprehensive feature offering with a more modern and user-friendly interface. With Sourcegraph, you can search entire codebases across multiple code hosts. The tool came along in 2017 and is gradually becoming the \"go-to\" tool when it comes to code search. Sourcegraph has overtaken OpenGrok in popularity amongst developers when comparing Google trends and GitHub activity and stars. Consider OpenGrok if it's already the tool your company/peers use for code search and navigation. Consider SourceGraph if you are looking for a modern, well maintained and comprehensive code search and intelligence tool.","title":"OpenGrok vs Sourcegraph"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-github","text":"GitHub is a code hosting platform with version control (Git) and collaboration features while OpenGrok is a code search and cross-referencing engine. Consider GitHub for hosting your code to make use of their version control and collaboration features. Consider OpenGrok if you need to add the power of code search and cross-referencing on top of your version control service/platform, ie. integrating OpenGrok with your GitHub repositories.","title":"OpenGrok vs GitHub"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-fisheye","text":"Fisheye is a commercial revision-control browser and search engine owned by Atlassian Inc. It is freely available to open-source projects and non-profits. With Fisheye, developers can search code, visualize and report on activity, and search through commits, files, revisions or teammates across SVN, Git, Mercurial, CVS and Perforce. While OpenGrok is a similar code search and cross-referencing engine, it has superior code search capabilities and supports multiple version control systems. However, OpenGrok falls short on a few key features like visual reports on activity. Consider Fisheye if your team uses Jira for easy integration and collaboration, or if you have a need for the reporting features that Fisheye provides. Consider OpenGrok if you are already accustomed to the OpenGrok workflow or if you use a version control system that is not supported by Fisheye.","title":"OpenGrok vs Fisheye"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-source-insight","text":"OpenGrok is a fast source code search and cross-reference engine while Source Insight is a programming editor, code browser and analyzer that helps developers understand code. Source Insight provides syntax highlighting, code navigation and customizable keyboard shortcuts. It goes beyond editing functionality and is a tool to understand a large source codebase. For this reason, it\u2019s called a \"program editor and analyzer\u201d. Consider OpenGrok if you are simply looking for a code search and cross-referencing engine to bolt on top of your existing workflow. Consider Source Insight if you are looking for an all-in-one programming tool that includes code search and collaboration features along with code analysis.","title":"OpenGrok vs Source Insight"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#opengrok-vs-elasticsearch","text":"OpenGrok is a universal code search and navigation tool for developers. OpenGrok is a stand-alone tool with its own search engine. Elasticsearch is a low-level search engine that other applications can use to provide search functionality. Elasticsearch is not an end-user product, it's just a search engine that provides low-level indexing and query APIs to your own applications, but you need to build the UI, syncing, analysis, deployment, etc. yourself. Consider Elasticsearch if you plan to build your own application with strong search capabilities. Consider OpenGrok if you are looking for a stand-alone code search and navigation tool.","title":"OpenGrok vs Elasticsearch"},{"location":"opengrok-vs-sourcegraph-vs-github-vs-fisheye-vs-source-insight-vs-elasticsearch/#github-vs-sourcegraph","text":"GitHub is a code host with version control functionality using Git. Sourcegraph is a web-based code search and navigation tool for developers. Sourcegraph's superior search functionality can easily be added on top of GitHub with Sourcegraph integration for larger organizations. Consider GitHub alone if you work in a small organization where GitHub's search functionality covers your needs. Consider Sourcegraph if you work in a larger organization and need more powerful search and collaboration functionality.","title":"GitHub vs Sourcegraph"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/","text":"PyCharm vs Spyder vs Jupyter vs Visual Studio vs Anaconda vs IntelliJ PyCharm vs Spyder PyCharm and Spyder are both cross-platform IDEs (Integrated Development Environments) featuring many helpful and intelligent features such as code completion, syntax highlighting and style analysis. However, Spyder is a lightweight IDE specifically designed for scientific Python development while PyCharm is more resource-intensive and much more powerful for programming. Consider PyCharm if you plan to build large, complex applications where you\u2019ll have a need for features like version control, code snippets, safe refactoring and an integrated project browser. Consider Spyder if you want a lightweight developer environment specifically for scientific Python applications. PyCharm vs Jupyter Jupyter is an IPython notebook that allows you to combine code, text and visualizations in one document while PyCharm is a featureful IDE for Python applications. Consider Jupyter if you want to easily present and share data visualizations along with code and text. Consider PyCharm if you want to work on complex projects which contain multiple scripts that interface with each other. PyCharm vs Visual Studio PyCharm and Visual Studio Code (VS Code) are both very popular and featureful IDEs. However, PyCharm is tailored for Python and you'll have to install other IDEs for other languages. Visual Studio is more modular, it only needs to know what type of project you are working in and it will automatically enable the required plugins. It\u2019s worth noting that PyCharm is very resource-intensive and performs much slower than Visual Studio. Consider PyCharm if you'll be working mainly with Python. Consider Visual Studio if you need to work with multiple languages and want the flexibility to customize your IDE. PyCharm vs Anaconda Anaconda is a Python distribution (set of libraries) focussed on data-driven projects while PyCharm is an IDE that also includes built-in support for Anaconda. Consider Anaconda if you want to perform only data science tasks with access to many data science packages. Consider PyCharm if you require flexibility to work on different types of projects but still have the need to use Anaconda for data-driven projects. PyCharm vs IntelliJ IntelliJ and PyCharm are both IDEs built by JetBrains. However, IntelliJ is tailored for Java while PyCharm is tailored for Python. Consider IntelliJ if you'll be coding mainly in Java. Consider PyCharm if you'll be coding mainly in Python. Jupyter vs Spyder Jupyter is an interactive Python notebook where you can run code, visualize data and include text all in one document, while Spyder is an IDE specifically for scientific programming in Python. Consider Jupyter if you work on data-driven projects where you need to easily present data to a non-technical audience. Consider Spyder for building data science applications with multiple scripts that reference each other. Intellij vs Visual Studio Intellij is an IDE built for Java while Visual Studio is a fully customizable IDE that supports almost any programming language. Consider IntelliJ if you code mainly in Java Consider Visual Studio if you need the flexibility to customize your IDE based on the language and frameworks required by a certain project.","title":"PyCharm vs Spyder vs Jupyter vs Visual Studio vs Anaconda vs IntelliJ"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij","text":"","title":"PyCharm vs Spyder vs Jupyter vs Visual Studio vs Anaconda vs IntelliJ"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-spyder","text":"PyCharm and Spyder are both cross-platform IDEs (Integrated Development Environments) featuring many helpful and intelligent features such as code completion, syntax highlighting and style analysis. However, Spyder is a lightweight IDE specifically designed for scientific Python development while PyCharm is more resource-intensive and much more powerful for programming. Consider PyCharm if you plan to build large, complex applications where you\u2019ll have a need for features like version control, code snippets, safe refactoring and an integrated project browser. Consider Spyder if you want a lightweight developer environment specifically for scientific Python applications.","title":"PyCharm vs Spyder"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-jupyter","text":"Jupyter is an IPython notebook that allows you to combine code, text and visualizations in one document while PyCharm is a featureful IDE for Python applications. Consider Jupyter if you want to easily present and share data visualizations along with code and text. Consider PyCharm if you want to work on complex projects which contain multiple scripts that interface with each other.","title":"PyCharm vs Jupyter"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-visual-studio","text":"PyCharm and Visual Studio Code (VS Code) are both very popular and featureful IDEs. However, PyCharm is tailored for Python and you'll have to install other IDEs for other languages. Visual Studio is more modular, it only needs to know what type of project you are working in and it will automatically enable the required plugins. It\u2019s worth noting that PyCharm is very resource-intensive and performs much slower than Visual Studio. Consider PyCharm if you'll be working mainly with Python. Consider Visual Studio if you need to work with multiple languages and want the flexibility to customize your IDE.","title":"PyCharm vs Visual Studio"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-anaconda","text":"Anaconda is a Python distribution (set of libraries) focussed on data-driven projects while PyCharm is an IDE that also includes built-in support for Anaconda. Consider Anaconda if you want to perform only data science tasks with access to many data science packages. Consider PyCharm if you require flexibility to work on different types of projects but still have the need to use Anaconda for data-driven projects.","title":"PyCharm vs Anaconda"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#pycharm-vs-intellij","text":"IntelliJ and PyCharm are both IDEs built by JetBrains. However, IntelliJ is tailored for Java while PyCharm is tailored for Python. Consider IntelliJ if you'll be coding mainly in Java. Consider PyCharm if you'll be coding mainly in Python.","title":"PyCharm vs IntelliJ"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#jupyter-vs-spyder","text":"Jupyter is an interactive Python notebook where you can run code, visualize data and include text all in one document, while Spyder is an IDE specifically for scientific programming in Python. Consider Jupyter if you work on data-driven projects where you need to easily present data to a non-technical audience. Consider Spyder for building data science applications with multiple scripts that reference each other.","title":"Jupyter vs Spyder"},{"location":"pycharm-vs-spyder-vs-jupyter-vs-visual-studio-vs-anaconda-vs-intellij/#intellij-vs-visual-studio","text":"Intellij is an IDE built for Java while Visual Studio is a fully customizable IDE that supports almost any programming language. Consider IntelliJ if you code mainly in Java Consider Visual Studio if you need the flexibility to customize your IDE based on the language and frameworks required by a certain project.","title":"Intellij vs Visual Studio"},{"location":"raspberry-pi-vs-arduino/","text":"Raspberry Pi vs Arduino Introduction The Raspberry Pi and the Arduino are often seen as the same thing whereas in fact they are two very different devices. Both come with General Purpose Input Output (GPIO) pins and are widely used to interact with other electronic devices such as sensors and motors; however, the Raspberry Pi is a fully fledged single-board computer (SBC) while the Arduino is simply a microcontroller that can handle only a single process at a time. Both devices were designed as teaching tools for a wide variety of subjects including computer science and \u201cinternet of things\u201d (IoT) applications. Over the years these devices have become increasingly powerful and today are widely used to develop proof-of-concept (POC) solutions that lay the foundation for much larger industrial applications. The Raspberry Pi The Raspberry Pi was developed in the United Kingdom at the University of Cambridge\u2019s Computer Laboratory in 2006 as a teaching tool for computer science students and was publicly released in 2012. It was developed to give students a cheap hackable computer on which they could safely tinker and test things out, allowing them to apply what they learn in a practical manner and experience first-hand the capabilities of computers. The Raspberry Pi is closed-source hardware and is produced only by the Raspberry Pi Foundation. Luckily there is a large community of engineers, enthusiasts and hobbyists who have created and shared ample resources like open-source projects and guides for you to learn from. Being a fully functional computer, the Raspberry Pi has its own microprocessor and memory, and can run a variety of different operating systems. It is also equipped with USB ports, audio output, HDMI graphic output and networking capabilities such as Ethernet, Wi-Fi and Bluetooth. Although the Raspberry Pi comes with a lot of features out of the box, it does not have everything. Hundreds of expansion boards, called HATs (Hardware Attached on Top), have been developed to add more functionality to the Pi. You can find all kinds of HATs that fit on top of the existing pins and can be stacked to add features like screens, LoRa (Long Range) chips, or another Pi to build clusters. The Raspberry Pi has its own flavor of the Linux OS called Raspberry Pi OS, previously known as Raspbian. Raspberry Pi OS comes pre-installed with software for education, programming and general use such as an Office suite, Scratch, Python, and Java. There are a variety of different models, the most popular today being the Raspberry Pi 3+, which is the model we will look at in this article. Strengths Stronger and quicker processor to run multiple software applications. Built-in networking capabilities: Ethernet, Wi-Fi and Bluetooth. OS can be switched. Built-in audio output, camera port, multiple USB ports, and HDMI output. Great to use as a desktop computer, media device, or retro gaming console. A great device to start learning and experimenting with programming. Best for projects where you need to connect to the internet and run multiple programs at the same time. Weaknesses Time-consuming setup. Need extra components to get started (screen, mouse, keyboard, etc.). Need to install programs for specific use cases and keep them updated with the OS. Can be more expensive if you just need a basic microcontroller. Does not support analog input out of the box. Higher power usage and more difficult to connect to a battery. The Arduino The Arduino was developed in Italy as a single-board microcontroller in the year 2000. It was designed to be a prototyping development board for connecting devices such as sensors and motors to a network. The main difference between the Arduino and the Raspberry Pi is that the Arduino is not a computer and cannot run its own OS. The Arduino is only part of a computer: a microcontroller that can run a single program at a time. The board comes with plenty of digital and analog I/O pins which can be connected to other electronic devices. When it comes to connecting everyday electronic devices to a system, collecting data with sensors, and controlling switches, the Arduino is the first choice for most. It is a simple plug-and-play device that can get your project started effortlessly by connecting it to a computer via USB, and loading your code through the Arduino IDE. The Arduino has its own simplified version of the C++ programming language; however, it supports code written in C or C++ and there are some workarounds to make other programming languages work with it. In order to add certain functionality to the Arduino, a lot of expansion boards and modules have been developed. These expansion boards are called shields and most of them were developed to easily add functionality by simply attaching them to the Arduino board. Unlike the Raspberry Pi, the Arduino is a fully open-source hardware and software project. Strengths Can connect analog components easily. Variety of shields that can add functionality. Easy to get started: just connect USB, load code, and run. No software or OS to be installed. Price is lower when you only need a microcontroller. Best for projects where you collect data from sensors and only need one program to work with the data. Low power usage and can easily be connected to a battery. Weaknesses Limited resources and can only run one program at a time. No network connectivity out of the box. Bigger learning curve with C/C++ language. Side-by-side comparison Arduino Uno Raspberry Pi 3 Model B+ Price $25 $40 Size 68.6 mm \u00d7 53.3 mm 8.6 cm \u00d7 5.4 cm \u00d7 1.7 cm Memory 2 KB 1 GB Clock speed 16 MHz 1.4 GHz On-board network None 2.4 & 5 GHz 802.11 b/g/n/ac Wi-Fi; Bluetooth 4.2; gigabit Ethernet Multitasking No Yes Input voltage 5 V 5 V Flash 32 KB SD card GPIO (pins) 20 GPIO (14 digital; 6 analog) (28 pins total) 28 GPIO (0 analog) (40 pins total) Power output (pins) 40 mA 16 mA Idle power usage 50 mA 700+ mA USB 1; input only 4; peripherals OK Operating system None Linux distributions Integrated development environment Arduino IDE Scratch, IDLE, Python, Java, anything with Linux support Which one to use? Now that you have a better idea of what these devices are and what their purpose is you might have already concluded that the answer is: it depends. Both devices can be used in similar projects; however, because they are very different devices, one might be better than the other depending on your project\u2019s requirements. Keeping the requirements of your project in mind, consider these factors when making your choice: scalability, functionality, flexibility, cost, power requirements, environmental conditions, and storage capacity. Use the Raspberry Pi: If you want the functionality of a desktop computer or you want to use it as a media device with a screen, etc. If you are just starting out with programming and want to explore and learn different programming languages. If you have a need for more processing power, for example a central server, a network gateway, a web server, a media device, or a small desktop computer. If you want to learn or experiment with building a supercomputer. The Raspberry Pi is stackable which allows you to build clusters of multiple Raspberry Pis and learn how to combine the resources of many nodes. If you need to run specific software that the Arduino does not support. When you are planning to run multiple programs at once. If you are already proficient in the Python programming language. When the environment is easily accessible and has a sufficient and stable power source. In applications where processing is vital. If a system needs to collect data from multiple sensors, pull or push data to or from the internet, connect to wireless devices, or provide complex output on a display. If you are looking for an all-in-one solution. Use the Arduino: If you simply want to control some electronics. If you are just starting out with electronics and IoT use cases. If you are already proficient at C programming. If you want to write a program to it, connect a battery (solar charger) and place it somewhere with sensors or electronics attached that send the data back to a database or central server. When you only need to run one process and you want to leave it running repeatedly for an extended period of time without any issues. When the environment does not have a stable power supply and you want to incorporate a battery or solar panel. If you want to read analog sensors in real time. Best of both worlds While it is clear that these are two very different devices, they are often used together to take advantage of their respective strengths. Because the Raspberry Pi is a few thousand times more powerful than the Arduino, resources are often wasted when you use a Raspberry Pi to connect to a single sensor or run a single small program. However, this makes it the perfect candidate for controlling multiple Arduinos, connecting to the internet and running web applications of a complete IoT system. A Raspberry Pi and an Arduino can easily be connected with the help of PySerial (https://pypi.org/project/pyserial/), a Python library for setting up serial communication. This allows for two-way communication where your more powerful Raspberry Pi can be used to manage multiple Arduinos. Often the Raspberry Pi is used as the server and the Arduinos are connected to it as nodes. For example, you can have Arduinos connected to sensors to collect data which you send to a Raspberry Pi which then uses that data to send new instructions to more Arduinos connected to valves, motors, or other electronics. Conclusion If you need processing power, want to run multiple processes at the same time, connect to the internet, or have the need for media capabilities then the Raspberry Pi is your best option. If you want a quick startup, low power usage, easy connection of sensors and only need to run a single process at a time then the Arduino is the most viable option. If you are beyond learning the basics and you are looking to build a larger solution with multiple sensors and electronics then consider using both as a system. It is up to you to decide which device aligns best with your requirements.","title":"Raspberry Pi vs Arduino"},{"location":"raspberry-pi-vs-arduino/#raspberry-pi-vs-arduino","text":"","title":"Raspberry Pi vs Arduino"},{"location":"raspberry-pi-vs-arduino/#introduction","text":"The Raspberry Pi and the Arduino are often seen as the same thing whereas in fact they are two very different devices. Both come with General Purpose Input Output (GPIO) pins and are widely used to interact with other electronic devices such as sensors and motors; however, the Raspberry Pi is a fully fledged single-board computer (SBC) while the Arduino is simply a microcontroller that can handle only a single process at a time. Both devices were designed as teaching tools for a wide variety of subjects including computer science and \u201cinternet of things\u201d (IoT) applications. Over the years these devices have become increasingly powerful and today are widely used to develop proof-of-concept (POC) solutions that lay the foundation for much larger industrial applications.","title":"Introduction"},{"location":"raspberry-pi-vs-arduino/#the-raspberry-pi","text":"The Raspberry Pi was developed in the United Kingdom at the University of Cambridge\u2019s Computer Laboratory in 2006 as a teaching tool for computer science students and was publicly released in 2012. It was developed to give students a cheap hackable computer on which they could safely tinker and test things out, allowing them to apply what they learn in a practical manner and experience first-hand the capabilities of computers. The Raspberry Pi is closed-source hardware and is produced only by the Raspberry Pi Foundation. Luckily there is a large community of engineers, enthusiasts and hobbyists who have created and shared ample resources like open-source projects and guides for you to learn from. Being a fully functional computer, the Raspberry Pi has its own microprocessor and memory, and can run a variety of different operating systems. It is also equipped with USB ports, audio output, HDMI graphic output and networking capabilities such as Ethernet, Wi-Fi and Bluetooth. Although the Raspberry Pi comes with a lot of features out of the box, it does not have everything. Hundreds of expansion boards, called HATs (Hardware Attached on Top), have been developed to add more functionality to the Pi. You can find all kinds of HATs that fit on top of the existing pins and can be stacked to add features like screens, LoRa (Long Range) chips, or another Pi to build clusters. The Raspberry Pi has its own flavor of the Linux OS called Raspberry Pi OS, previously known as Raspbian. Raspberry Pi OS comes pre-installed with software for education, programming and general use such as an Office suite, Scratch, Python, and Java. There are a variety of different models, the most popular today being the Raspberry Pi 3+, which is the model we will look at in this article.","title":"The Raspberry Pi"},{"location":"raspberry-pi-vs-arduino/#strengths","text":"Stronger and quicker processor to run multiple software applications. Built-in networking capabilities: Ethernet, Wi-Fi and Bluetooth. OS can be switched. Built-in audio output, camera port, multiple USB ports, and HDMI output. Great to use as a desktop computer, media device, or retro gaming console. A great device to start learning and experimenting with programming. Best for projects where you need to connect to the internet and run multiple programs at the same time.","title":"Strengths"},{"location":"raspberry-pi-vs-arduino/#weaknesses","text":"Time-consuming setup. Need extra components to get started (screen, mouse, keyboard, etc.). Need to install programs for specific use cases and keep them updated with the OS. Can be more expensive if you just need a basic microcontroller. Does not support analog input out of the box. Higher power usage and more difficult to connect to a battery.","title":"Weaknesses"},{"location":"raspberry-pi-vs-arduino/#the-arduino","text":"The Arduino was developed in Italy as a single-board microcontroller in the year 2000. It was designed to be a prototyping development board for connecting devices such as sensors and motors to a network. The main difference between the Arduino and the Raspberry Pi is that the Arduino is not a computer and cannot run its own OS. The Arduino is only part of a computer: a microcontroller that can run a single program at a time. The board comes with plenty of digital and analog I/O pins which can be connected to other electronic devices. When it comes to connecting everyday electronic devices to a system, collecting data with sensors, and controlling switches, the Arduino is the first choice for most. It is a simple plug-and-play device that can get your project started effortlessly by connecting it to a computer via USB, and loading your code through the Arduino IDE. The Arduino has its own simplified version of the C++ programming language; however, it supports code written in C or C++ and there are some workarounds to make other programming languages work with it. In order to add certain functionality to the Arduino, a lot of expansion boards and modules have been developed. These expansion boards are called shields and most of them were developed to easily add functionality by simply attaching them to the Arduino board. Unlike the Raspberry Pi, the Arduino is a fully open-source hardware and software project.","title":"The Arduino"},{"location":"raspberry-pi-vs-arduino/#strengths_1","text":"Can connect analog components easily. Variety of shields that can add functionality. Easy to get started: just connect USB, load code, and run. No software or OS to be installed. Price is lower when you only need a microcontroller. Best for projects where you collect data from sensors and only need one program to work with the data. Low power usage and can easily be connected to a battery.","title":"Strengths"},{"location":"raspberry-pi-vs-arduino/#weaknesses_1","text":"Limited resources and can only run one program at a time. No network connectivity out of the box. Bigger learning curve with C/C++ language.","title":"Weaknesses"},{"location":"raspberry-pi-vs-arduino/#side-by-side-comparison","text":"Arduino Uno Raspberry Pi 3 Model B+ Price $25 $40 Size 68.6 mm \u00d7 53.3 mm 8.6 cm \u00d7 5.4 cm \u00d7 1.7 cm Memory 2 KB 1 GB Clock speed 16 MHz 1.4 GHz On-board network None 2.4 & 5 GHz 802.11 b/g/n/ac Wi-Fi; Bluetooth 4.2; gigabit Ethernet Multitasking No Yes Input voltage 5 V 5 V Flash 32 KB SD card GPIO (pins) 20 GPIO (14 digital; 6 analog) (28 pins total) 28 GPIO (0 analog) (40 pins total) Power output (pins) 40 mA 16 mA Idle power usage 50 mA 700+ mA USB 1; input only 4; peripherals OK Operating system None Linux distributions Integrated development environment Arduino IDE Scratch, IDLE, Python, Java, anything with Linux support","title":"Side-by-side comparison"},{"location":"raspberry-pi-vs-arduino/#which-one-to-use","text":"Now that you have a better idea of what these devices are and what their purpose is you might have already concluded that the answer is: it depends. Both devices can be used in similar projects; however, because they are very different devices, one might be better than the other depending on your project\u2019s requirements. Keeping the requirements of your project in mind, consider these factors when making your choice: scalability, functionality, flexibility, cost, power requirements, environmental conditions, and storage capacity.","title":"Which one to use?"},{"location":"raspberry-pi-vs-arduino/#use-the-raspberry-pi","text":"If you want the functionality of a desktop computer or you want to use it as a media device with a screen, etc. If you are just starting out with programming and want to explore and learn different programming languages. If you have a need for more processing power, for example a central server, a network gateway, a web server, a media device, or a small desktop computer. If you want to learn or experiment with building a supercomputer. The Raspberry Pi is stackable which allows you to build clusters of multiple Raspberry Pis and learn how to combine the resources of many nodes. If you need to run specific software that the Arduino does not support. When you are planning to run multiple programs at once. If you are already proficient in the Python programming language. When the environment is easily accessible and has a sufficient and stable power source. In applications where processing is vital. If a system needs to collect data from multiple sensors, pull or push data to or from the internet, connect to wireless devices, or provide complex output on a display. If you are looking for an all-in-one solution.","title":"Use the Raspberry Pi:"},{"location":"raspberry-pi-vs-arduino/#use-the-arduino","text":"If you simply want to control some electronics. If you are just starting out with electronics and IoT use cases. If you are already proficient at C programming. If you want to write a program to it, connect a battery (solar charger) and place it somewhere with sensors or electronics attached that send the data back to a database or central server. When you only need to run one process and you want to leave it running repeatedly for an extended period of time without any issues. When the environment does not have a stable power supply and you want to incorporate a battery or solar panel. If you want to read analog sensors in real time.","title":"Use the Arduino:"},{"location":"raspberry-pi-vs-arduino/#best-of-both-worlds","text":"While it is clear that these are two very different devices, they are often used together to take advantage of their respective strengths. Because the Raspberry Pi is a few thousand times more powerful than the Arduino, resources are often wasted when you use a Raspberry Pi to connect to a single sensor or run a single small program. However, this makes it the perfect candidate for controlling multiple Arduinos, connecting to the internet and running web applications of a complete IoT system. A Raspberry Pi and an Arduino can easily be connected with the help of PySerial (https://pypi.org/project/pyserial/), a Python library for setting up serial communication. This allows for two-way communication where your more powerful Raspberry Pi can be used to manage multiple Arduinos. Often the Raspberry Pi is used as the server and the Arduinos are connected to it as nodes. For example, you can have Arduinos connected to sensors to collect data which you send to a Raspberry Pi which then uses that data to send new instructions to more Arduinos connected to valves, motors, or other electronics.","title":"Best of both worlds"},{"location":"raspberry-pi-vs-arduino/#conclusion","text":"If you need processing power, want to run multiple processes at the same time, connect to the internet, or have the need for media capabilities then the Raspberry Pi is your best option. If you want a quick startup, low power usage, easy connection of sensors and only need to run a single process at a time then the Arduino is the most viable option. If you are beyond learning the basics and you are looking to build a larger solution with multiple sensors and electronics then consider using both as a system. It is up to you to decide which device aligns best with your requirements.","title":"Conclusion"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/","text":"Scikit-Learn vs. TensorFlow vs. PyTorch vs. Keras Scikit-Learn vs. TensorFlow Scikit-Learn is a general machine learning library for Python. Users may find it has a lower barrier to entry as it is built on top of and integrates with commonly used libraries such as NumPy, SciPy, matplotlib and pandas. On the other hand, TensorFlow, whilst also an open-source machine learning library, specializes on deep learning and neural networks with support for several programming languages such as Python, C/C++, Java, Javascript, etc. Consider Scikit-Learn if you are new to machine learning and/or are developing something using non-neaural network algorithms. Consider TensorFlow if you want to use a deep learning approach in conjunction with hardware acceleration through GPUs, TPUs or a cluster of computers which Scikit-Learn does not natively support. PyTorch vs. Scikit-Learn PyTorch is a deep learning software library for Python, C++ and Julia. PyTorch is primarily used for end-to-end building and training of deep neural networks with the ability to create custom models and learning algorithms. Scikit-Learn is a library for traditional machine learning algorithms used for clustering, classification, regression, etc. Scikit-Learn's black-box nature makes it more accessible to those who are realively new to machine learning. Consider PyTorch if you're developing applications that have computationally expensive tasks such as natural language processing, computer vision, etc. With Pytorch, you are also able to utilize GPU acceleration to your advantage. Consider Scikit-Learn if you're developing a small exploratory project that doesn't require a substantial amount of data. With Scikit-Learn your focus would not be on customisation but rather on the speed and user-friendliness of the machine learning algorithms. Keras vs. Scikit-Learn Keras is a high-level deep learning framework, that abstracts many of the low-level details and computations away by handing them off to TensorFlow. This allows Keras to have reduced code complexity despite being a deep learning framework. Scikit-Learn has an even greater level of abstraction for common machine learning algortihms. Scikit-Learn does not have native support for GPU computing and deep learning. Consider Keras if your application/model has to use neural networks to learn from large amounts of data. Keras also caters for those who are fairly new to deep learning. Consider Scikit-Learn if you require a model for statistical purposes, predictions, classification, clustering, etc. Scikit-Learn works well with relatively small datasets which require general machine learning computations. PyTorch vs. TensorFlow PyTorch is a relatively younger deep learning framework with a pythonic and object oriented approach. PyTorch allows for comparatively superior debugging with more choices. TensorFlow, similarly, is a low-level deep learning library. TensorFlow has been around for longer and also provides high-level APIs such as Keras - albeit with less computational power. TensorFlow currently has broader adoption and a superior visualization tool - TensorBoard (PyTorch also integrates with TensorBoard). Consider PyTorch if Python is central to your development. PyTorch currently has more straightened debugging capabilities. Consider TensorFlow if you want a library compatible with various coding languages such as C/C++, Java, JavaScript, Go, etc. TensorFlow also has extensive multi-platform support. Keras vs. TensorFlow Keras acts as a deep learning-centric library running on top of TensorFlow. This abstraction allows Keras to be better suited for developers to build, train, and evaluate models with relatice 'ease'. Keras supports Python and R while Tensorflow supports the major - Python, C++, Java, and Javascript - languages with Go and Swift being unofficial and archived respectively. TensorFlow runs as a back-end to Keras, but also as it's own standalone library for low level computations. Consider Keras if you are relatively new to deep learning or looking to use a high level api utilizing the TensorFlow framework to your advantage. As with any library, Keras takes into account best practices with comparatively less complexity. Consider TensorFlow if you require greater funtionality and performance on large datasets. TensorFlow requires you to be slightly adept with deep learning to capitalize on what it has to offer. Keras vs. PyTorch Keras is a software library focused on deep learning. Keras functions as a high-level interface for the TensorFlow library, resulting in comparatively slower computations, but less complexity. PyTorch is a low-level computation framework with superior debugging, pliability and performance capabilities. Consider Keras if want to use deep learning algorithms and models with relatively small datasets. Keras is more readable and approachable to beginners. Consider PyTorch if you have deep learning experience and/or want to create a custom model. Keep in mind that, natively, PyTorch is not capable of running on a browser (It is currently possible using through a conversion process that converts PyTorch to TensorFlow.js).","title":"Scikit-Learn vs. TensorFlow vs. PyTorch vs. Keras"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#scikit-learn-vs-tensorflow-vs-pytorch-vs-keras","text":"","title":"Scikit-Learn vs. TensorFlow vs. PyTorch vs. Keras"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#scikit-learn-vs-tensorflow","text":"Scikit-Learn is a general machine learning library for Python. Users may find it has a lower barrier to entry as it is built on top of and integrates with commonly used libraries such as NumPy, SciPy, matplotlib and pandas. On the other hand, TensorFlow, whilst also an open-source machine learning library, specializes on deep learning and neural networks with support for several programming languages such as Python, C/C++, Java, Javascript, etc. Consider Scikit-Learn if you are new to machine learning and/or are developing something using non-neaural network algorithms. Consider TensorFlow if you want to use a deep learning approach in conjunction with hardware acceleration through GPUs, TPUs or a cluster of computers which Scikit-Learn does not natively support.","title":"Scikit-Learn vs. TensorFlow"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#pytorch-vs-scikit-learn","text":"PyTorch is a deep learning software library for Python, C++ and Julia. PyTorch is primarily used for end-to-end building and training of deep neural networks with the ability to create custom models and learning algorithms. Scikit-Learn is a library for traditional machine learning algorithms used for clustering, classification, regression, etc. Scikit-Learn's black-box nature makes it more accessible to those who are realively new to machine learning. Consider PyTorch if you're developing applications that have computationally expensive tasks such as natural language processing, computer vision, etc. With Pytorch, you are also able to utilize GPU acceleration to your advantage. Consider Scikit-Learn if you're developing a small exploratory project that doesn't require a substantial amount of data. With Scikit-Learn your focus would not be on customisation but rather on the speed and user-friendliness of the machine learning algorithms.","title":"PyTorch vs. Scikit-Learn"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#keras-vs-scikit-learn","text":"Keras is a high-level deep learning framework, that abstracts many of the low-level details and computations away by handing them off to TensorFlow. This allows Keras to have reduced code complexity despite being a deep learning framework. Scikit-Learn has an even greater level of abstraction for common machine learning algortihms. Scikit-Learn does not have native support for GPU computing and deep learning. Consider Keras if your application/model has to use neural networks to learn from large amounts of data. Keras also caters for those who are fairly new to deep learning. Consider Scikit-Learn if you require a model for statistical purposes, predictions, classification, clustering, etc. Scikit-Learn works well with relatively small datasets which require general machine learning computations.","title":"Keras vs. Scikit-Learn"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#pytorch-vs-tensorflow","text":"PyTorch is a relatively younger deep learning framework with a pythonic and object oriented approach. PyTorch allows for comparatively superior debugging with more choices. TensorFlow, similarly, is a low-level deep learning library. TensorFlow has been around for longer and also provides high-level APIs such as Keras - albeit with less computational power. TensorFlow currently has broader adoption and a superior visualization tool - TensorBoard (PyTorch also integrates with TensorBoard). Consider PyTorch if Python is central to your development. PyTorch currently has more straightened debugging capabilities. Consider TensorFlow if you want a library compatible with various coding languages such as C/C++, Java, JavaScript, Go, etc. TensorFlow also has extensive multi-platform support.","title":"PyTorch vs. TensorFlow"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#keras-vs-tensorflow","text":"Keras acts as a deep learning-centric library running on top of TensorFlow. This abstraction allows Keras to be better suited for developers to build, train, and evaluate models with relatice 'ease'. Keras supports Python and R while Tensorflow supports the major - Python, C++, Java, and Javascript - languages with Go and Swift being unofficial and archived respectively. TensorFlow runs as a back-end to Keras, but also as it's own standalone library for low level computations. Consider Keras if you are relatively new to deep learning or looking to use a high level api utilizing the TensorFlow framework to your advantage. As with any library, Keras takes into account best practices with comparatively less complexity. Consider TensorFlow if you require greater funtionality and performance on large datasets. TensorFlow requires you to be slightly adept with deep learning to capitalize on what it has to offer.","title":"Keras vs. TensorFlow"},{"location":"scikit-learn-vs-tensorflow-vs-pytorch-vs-keras/#keras-vs-pytorch","text":"Keras is a software library focused on deep learning. Keras functions as a high-level interface for the TensorFlow library, resulting in comparatively slower computations, but less complexity. PyTorch is a low-level computation framework with superior debugging, pliability and performance capabilities. Consider Keras if want to use deep learning algorithms and models with relatively small datasets. Keras is more readable and approachable to beginners. Consider PyTorch if you have deep learning experience and/or want to create a custom model. Keep in mind that, natively, PyTorch is not capable of running on a browser (It is currently possible using through a conversion process that converts PyTorch to TensorFlow.js).","title":"Keras vs. PyTorch"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/","text":"Tailwind CSS vs. Bootstrap vs. Material UI vs. Styled Components vs. Bulma vs. SASS When it comes to CSS frameworks, the sheer number of available options can sometimes be a major obstacle in itself. Let's take a look at some of the choices and the major differences between them to help you decide on a framework that works for you. Bootstrap vs. Tailwind CSS Bootstrap is a popular CSS framework that has been around for a decade(at the time of this article). Bootstrap takes on a responsive, mobile-first approach. Tailwind CSS is a relatively newer framework and way of styling HTML that challenges established conventions. Consider Bootstrap if you prefer an established design system that comes with predefined design templates. Consider Tailwind CSS if you are welcoming of using a newer approach that essentially populates your markup in an effort to create custom UI components. Material UI vs. Tailwind CSS Material UI is a React components library based on Google's Material design. On the other hand, Tailwind CSS is a CSS framework that comes with predefined classes (not components) as building blocks to design any UI. Consider Material UI if you are an avid React user and do not have the time to build a custom UI from scratch. Consider Tailwind CSS if you want to build a custom UI within your markup whilst writing almost no custom css. Styled Components vs. Tailwind CSS Styled Components is a React CSS-in-JavaScript framework you can use to write custom css using JavaScript. Tailwind CSS allows you to build UIs using multiple abbreviated class names as opposed to semantic classes. Consider Styled Components if you're looking to stay within the React ecosystem and create custom React/CSS components. Consider Tailwind CSS if you have no experience with JavaScript/React but still looking to create reusable custom components. Bulma vs. Tailwind CSS Although Bulma is a mobile-first CSS framework similar to Bootstrap, it is lightweight with a limited number of components and JavaScript exclusion. Tailwind CSS employs a different methodology that places best-practices on the back-burner in favour of flexible UI designing. Consider Bulma if you want to use CSS components to build responsive sites with a gentle learning curve. Consider Tailwind CSS for an un-opinionated approach to design using a fairly new framework and method utilizing micro classes in your markup. Sass vs. Tailwind CSS Sass generates CSS for you using it's own scripted language. Sass aims at being a concise way of writing CSS. With Tailwind you are not likely to write any CSS and but rather abbreviated classes such as flex , m-4 and bg-red-100 etc. in your markup file. Consider Sass if you would like to write much of the CSS yourself only with a more stable syntax. Consider Tailwind CSS if you want to quickly create designs using micro classes. Keep in mind this may be unreadable for non-Tailwind users. Bootstrap vs. Material UI Bootstrap is a beginner friendly framework that comes with pre-packaged UI components and JavaScript plugins that will do most of the heavy lifting when designing and building a website. Material UI also offers reusable pre-designed components and layouts, however, they are based on Google's Material design. Consider Bootstrap if you want to keep complexity low and still have a large number of options to pick from. Consider Material UI if you can use React and want a more stable implementation of a design system within React. Sass vs. Styled Components Sass , as a scripting language compiles into plain css which makes it debugging friendly. Styled components allows for creating customized and reusable components, but with the drawback of comparatively difficult debugging due to writing CSS in JavaScript. Styled components does have Sass support as well. Consider Sass if you essentially do not want to lock yourself into a specialized workflow with a steeper learning curve. Consider Styled Components if you want to have significantly less chances of overriding styling as styles are not globally scoped. Material UI vs. Styled Components Material UI is a CCS-in-JS framework that provides ready-to-use components, themes and user interfaces. Styled Components whilst similar to Material UI, gives you the ability to build custom CSS components. Consider Material UI if you want to significantly cut production time down by using a UI library with consistent designs and a vast community behind it. Consider Styled Components for a more hands on approach to creating custom UIs. Bootstrap vs. Bulma Bootstrap is a framework that has been around for far longer and so has built up an extensive set of design choices and community. Bulma can be seen as a smaller version of bootstrap with less complexities, providing beginners with comparable benefits to it's much larger -bootstrap- counterpart. Consider Bootstrap if you're looking to step up to a much larger design palette using a framework built on Sass. Keep in mind that bootstrap can sometimes be overly complex and encumbered leading to bulky apps/websites. Consider Bulma if you would much rather do without the complexities of bootstrap(i.e. javascript) whilst having some of the component creation taken care of by a tiny, non-intrusive framework. Bulma vs. Material UI Bulma is mobile-first CSS framework aimed at more simple-usage scenarios. It is pre-packaged a number of ready-to-use components. Material UI Makes use of a pre-defined Material design system for use in React. Besides basic components, Material UI also comes with UI elements like sliders, drop downs, navigation bars, etc. Consider Bulma If you to simply build a usable website with less time and complications. Consider Material UI if you want a robust, well-documented design system to use in your React app. Bootstrap vs. Sass Bootstrap , now built on Sass is a collection of pre designed UI components and best practices. Sass is a scripting language that provides a clearer, concise approach to writing custom css. Consider Bootstrap if you don't want to build a custom design from scratch, or just simply learn a popular CSS framework. Consider Sass if you want to write custom CSS with scripting benefits and tools such as nesting, mixins, and inheritance, whilst keeping your CSS fairly maintainable.","title":"Tailwind CSS vs. Bootstrap vs. Material UI vs. Styled Components vs. Bulma vs. SASS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass","text":"When it comes to CSS frameworks, the sheer number of available options can sometimes be a major obstacle in itself. Let's take a look at some of the choices and the major differences between them to help you decide on a framework that works for you.","title":"Tailwind CSS vs. Bootstrap vs. Material UI vs. Styled Components vs. Bulma vs. SASS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bootstrap-vs-tailwind-css","text":"Bootstrap is a popular CSS framework that has been around for a decade(at the time of this article). Bootstrap takes on a responsive, mobile-first approach. Tailwind CSS is a relatively newer framework and way of styling HTML that challenges established conventions. Consider Bootstrap if you prefer an established design system that comes with predefined design templates. Consider Tailwind CSS if you are welcoming of using a newer approach that essentially populates your markup in an effort to create custom UI components.","title":"Bootstrap vs. Tailwind CSS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#material-ui-vs-tailwind-css","text":"Material UI is a React components library based on Google's Material design. On the other hand, Tailwind CSS is a CSS framework that comes with predefined classes (not components) as building blocks to design any UI. Consider Material UI if you are an avid React user and do not have the time to build a custom UI from scratch. Consider Tailwind CSS if you want to build a custom UI within your markup whilst writing almost no custom css.","title":"Material UI vs. Tailwind CSS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#styled-components-vs-tailwind-css","text":"Styled Components is a React CSS-in-JavaScript framework you can use to write custom css using JavaScript. Tailwind CSS allows you to build UIs using multiple abbreviated class names as opposed to semantic classes. Consider Styled Components if you're looking to stay within the React ecosystem and create custom React/CSS components. Consider Tailwind CSS if you have no experience with JavaScript/React but still looking to create reusable custom components.","title":"Styled Components vs. Tailwind CSS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bulma-vs-tailwind-css","text":"Although Bulma is a mobile-first CSS framework similar to Bootstrap, it is lightweight with a limited number of components and JavaScript exclusion. Tailwind CSS employs a different methodology that places best-practices on the back-burner in favour of flexible UI designing. Consider Bulma if you want to use CSS components to build responsive sites with a gentle learning curve. Consider Tailwind CSS for an un-opinionated approach to design using a fairly new framework and method utilizing micro classes in your markup.","title":"Bulma  vs. Tailwind CSS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#sass-vs-tailwind-css","text":"Sass generates CSS for you using it's own scripted language. Sass aims at being a concise way of writing CSS. With Tailwind you are not likely to write any CSS and but rather abbreviated classes such as flex , m-4 and bg-red-100 etc. in your markup file. Consider Sass if you would like to write much of the CSS yourself only with a more stable syntax. Consider Tailwind CSS if you want to quickly create designs using micro classes. Keep in mind this may be unreadable for non-Tailwind users.","title":"Sass vs. Tailwind CSS"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bootstrap-vs-material-ui","text":"Bootstrap is a beginner friendly framework that comes with pre-packaged UI components and JavaScript plugins that will do most of the heavy lifting when designing and building a website. Material UI also offers reusable pre-designed components and layouts, however, they are based on Google's Material design. Consider Bootstrap if you want to keep complexity low and still have a large number of options to pick from. Consider Material UI if you can use React and want a more stable implementation of a design system within React.","title":"Bootstrap vs. Material UI"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#sass-vs-styled-components","text":"Sass , as a scripting language compiles into plain css which makes it debugging friendly. Styled components allows for creating customized and reusable components, but with the drawback of comparatively difficult debugging due to writing CSS in JavaScript. Styled components does have Sass support as well. Consider Sass if you essentially do not want to lock yourself into a specialized workflow with a steeper learning curve. Consider Styled Components if you want to have significantly less chances of overriding styling as styles are not globally scoped.","title":"Sass vs. Styled Components"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#material-ui-vs-styled-components","text":"Material UI is a CCS-in-JS framework that provides ready-to-use components, themes and user interfaces. Styled Components whilst similar to Material UI, gives you the ability to build custom CSS components. Consider Material UI if you want to significantly cut production time down by using a UI library with consistent designs and a vast community behind it. Consider Styled Components for a more hands on approach to creating custom UIs.","title":"Material UI vs. Styled Components"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bootstrap-vs-bulma","text":"Bootstrap is a framework that has been around for far longer and so has built up an extensive set of design choices and community. Bulma can be seen as a smaller version of bootstrap with less complexities, providing beginners with comparable benefits to it's much larger -bootstrap- counterpart. Consider Bootstrap if you're looking to step up to a much larger design palette using a framework built on Sass. Keep in mind that bootstrap can sometimes be overly complex and encumbered leading to bulky apps/websites. Consider Bulma if you would much rather do without the complexities of bootstrap(i.e. javascript) whilst having some of the component creation taken care of by a tiny, non-intrusive framework.","title":"Bootstrap vs. Bulma"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bulma-vs-material-ui","text":"Bulma is mobile-first CSS framework aimed at more simple-usage scenarios. It is pre-packaged a number of ready-to-use components. Material UI Makes use of a pre-defined Material design system for use in React. Besides basic components, Material UI also comes with UI elements like sliders, drop downs, navigation bars, etc. Consider Bulma If you to simply build a usable website with less time and complications. Consider Material UI if you want a robust, well-documented design system to use in your React app.","title":"Bulma  vs. Material UI"},{"location":"tailwind-css-vs-bootstrap-vs-material-ui-vs-styled-components-vs-bulma-vs-sass/#bootstrap-vs-sass","text":"Bootstrap , now built on Sass is a collection of pre designed UI components and best practices. Sass is a scripting language that provides a clearer, concise approach to writing custom css. Consider Bootstrap if you don't want to build a custom design from scratch, or just simply learn a popular CSS framework. Consider Sass if you want to write custom CSS with scripting benefits and tools such as nesting, mixins, and inheritance, whilst keeping your CSS fairly maintainable.","title":"Bootstrap vs. Sass"},{"location":"the-mlops-manifesto/","text":"The MLOps Manifesto Based on a transcription of https://www.youtube.com/watch?v=hqxQO7MoQIE We have a manifesto for MLOps. This is what we care about and why we get out of bed in the morning. It consists of four tests: \u267b\ufe0f Reproducible: Other people and teams should be able to reproduce your work months or years later without talking to you directly. \ud83d\udc69\u200d\ud83c\udfeb Accountable: We (and others) can trust the results of our model by recording exactly what data was used and how a decision was reached \ud83d\udc65 Collaborative: People can asynchronously fork and work on different models without creating a mess. \ud83d\udc49 Continuous: You can kind of apply these tests to your own MLOps pipelines and you can form an opinion about how mature you are compared to the different the different requirements. Reproducible The first requirement is that your model training and deployment pipelines have to be reproducible.Can someone else come along nine months later and retrain a model without talking to the original creator of that model? Let's say an old version of TensorFlow on an old data set with on a hardware that is sufficiently equivalent that they can retrain the models within a few percentage points - then you've got a reproducible MLOps pipeline. Nine months later you can't because you upgraded the version of TensorFlow on your development machines and the data has gone somewhere and you don't know where the data is gone the date has changed in your production database then you've failed the reproducibility test. If you fail the reproducibility test and you're in trouble from a governance and compliance perspective in some industries. Accountable The second test is that an MLOps pipeline should be accountable . We think about accountability from the same perspective that we hold humans accountable for their decision-making process and one of the ways in which you do that is you to specify * on what basis did you make your decision * on what basis question with machine learning as a minimum requirement not even going into the whole area of explain ability but as a minimum requirement you have to be able to say what version of the data was the model trained on so you need to be able to track the model back to the program where that model came from what data was trained on by whom and and so on the next point and it's especially pertinent at the moment is this Collaboration We want to do asynchronous collaboration. This is something that software DevOps has got sorted and MLOps doesn't yet. For example, my colleague Chris is working on a model I need to be able to make a fork of that model and I make changes to it without treading on Chris's toes. We need to collaborate asynchronously and and get useful work done. DevOps does this with a GitHub pull request style of collaboration that the data scientists are familiar with, but there are some challenges in making that possible for ML. Continuous Development should lead to automatic deployment : we should automatically deploy a model into a staging environment or production environment without manually emailing Jupiters and notebooks or TensorFlow files, or serialized test flow models, around because as soon as you start doing things manually then it introduces this possibility for human error. You have to be able to statistically monitor your models, and this is interesting because monitoring models is specifically is quite different to monitoring regular software. With regular software, you can monitor things like error-rates and know immediately if something is wrong. With machine learning models, they might give you perfectly normal latencies and error rates but the model itself has gone haywire. You can't verify a models predictions because if you could, you wouldn't need the model in the first place. That is, productdion data is unlabeled , so it's challenging to understand the behaviour of your model once it's running in production. You need to look statistically at e.g. the number of predictions it makes in certain classes, and if then page a human if the distribution varies from an expected distribution to make a call on if the world has chnaged or if the model has broken. This is especially a problem in computer vision where you get stupid things like suddenly it starts snowing and now your self-driving car can't recognise stop signs any more because it was never trained on identifying stop signs with snow in the background.","title":"The MLOps Manifesto"},{"location":"the-mlops-manifesto/#the-mlops-manifesto","text":"Based on a transcription of https://www.youtube.com/watch?v=hqxQO7MoQIE We have a manifesto for MLOps. This is what we care about and why we get out of bed in the morning. It consists of four tests: \u267b\ufe0f Reproducible: Other people and teams should be able to reproduce your work months or years later without talking to you directly. \ud83d\udc69\u200d\ud83c\udfeb Accountable: We (and others) can trust the results of our model by recording exactly what data was used and how a decision was reached \ud83d\udc65 Collaborative: People can asynchronously fork and work on different models without creating a mess. \ud83d\udc49 Continuous: You can kind of apply these tests to your own MLOps pipelines and you can form an opinion about how mature you are compared to the different the different requirements.","title":"The MLOps Manifesto"},{"location":"the-mlops-manifesto/#reproducible","text":"The first requirement is that your model training and deployment pipelines have to be reproducible.Can someone else come along nine months later and retrain a model without talking to the original creator of that model? Let's say an old version of TensorFlow on an old data set with on a hardware that is sufficiently equivalent that they can retrain the models within a few percentage points - then you've got a reproducible MLOps pipeline. Nine months later you can't because you upgraded the version of TensorFlow on your development machines and the data has gone somewhere and you don't know where the data is gone the date has changed in your production database then you've failed the reproducibility test. If you fail the reproducibility test and you're in trouble from a governance and compliance perspective in some industries.","title":"Reproducible"},{"location":"the-mlops-manifesto/#accountable","text":"The second test is that an MLOps pipeline should be accountable . We think about accountability from the same perspective that we hold humans accountable for their decision-making process and one of the ways in which you do that is you to specify * on what basis did you make your decision * on what basis question with machine learning as a minimum requirement not even going into the whole area of explain ability but as a minimum requirement you have to be able to say what version of the data was the model trained on so you need to be able to track the model back to the program where that model came from what data was trained on by whom and and so on the next point and it's especially pertinent at the moment is this","title":"Accountable"},{"location":"the-mlops-manifesto/#collaboration","text":"We want to do asynchronous collaboration. This is something that software DevOps has got sorted and MLOps doesn't yet. For example, my colleague Chris is working on a model I need to be able to make a fork of that model and I make changes to it without treading on Chris's toes. We need to collaborate asynchronously and and get useful work done. DevOps does this with a GitHub pull request style of collaboration that the data scientists are familiar with, but there are some challenges in making that possible for ML.","title":"Collaboration"},{"location":"the-mlops-manifesto/#continuous","text":"Development should lead to automatic deployment : we should automatically deploy a model into a staging environment or production environment without manually emailing Jupiters and notebooks or TensorFlow files, or serialized test flow models, around because as soon as you start doing things manually then it introduces this possibility for human error. You have to be able to statistically monitor your models, and this is interesting because monitoring models is specifically is quite different to monitoring regular software. With regular software, you can monitor things like error-rates and know immediately if something is wrong. With machine learning models, they might give you perfectly normal latencies and error rates but the model itself has gone haywire. You can't verify a models predictions because if you could, you wouldn't need the model in the first place. That is, productdion data is unlabeled , so it's challenging to understand the behaviour of your model once it's running in production. You need to look statistically at e.g. the number of predictions it makes in certain classes, and if then page a human if the distribution varies from an expected distribution to make a call on if the world has chnaged or if the model has broken. This is especially a problem in computer vision where you get stupid things like suddenly it starts snowing and now your self-driving car can't recognise stop signs any more because it was never trained on identifying stop signs with snow in the background.","title":"Continuous"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/","text":"The opinionated guide to setting up a Sourcegraph server for advanced code search If you've ever written code, you probably know that: \ud83d\udd0d Searching through examples of code is useful for so many things. \ud83e\udd26\u200d\u2642\ufe0f GitHub search kind of sucks. You might not have tried out advanced code search tools like Sourcegraph because getting started looks like too much effort. The Sourcegraph \"Getting Started\" page already has a ton of information about different ways to start using Sourcegraph, but here we'll go through an opinionated set up guide. Specifically, we'll: \u2601\ufe0f Set up Sourcegraph on a VPS (DigitalOcean in this case, but feel free to use your own cloud provider). \ud83d\ude8d Set up Nginx as reverse proxy. \ud83c\udfab Use LetsEncrypt to get an SSL certificate. \ud83d\udc69\u200d\ud83d\udcbb Integrate with GitHub to search through public and private repositories hosted there. This is a tradeoff between running Sourcegraph locally on your dev machine (where features would be limited), and installing it to a cluster (where set up would take longer). \ud83d\uddbc The end result of following this guide At the end of this guide, you'll have your own Sourcegraph server set up on a custom domain like sg.example.com . It will periodically fetch any repositories you are interested in from GitHub (private, public, or from your entire GitHub org) and update its index so that you have these at your fingertips. You'll be able to search through all your code using advanced syntax and better defaults. \u2611\ufe0f Requirements to follow along To follow along, you should: \ud83d\udcbb Be comfortable using Linux and SSH, connecting to a VPS and installing and configuring software. \ud83c\udf10 Have a custom domain where you can add new subdomains, e.g. through NameCheap or similar. \u2601\ufe0f Have an account at a cloud provider, such as DigitalOcean or AWS. \ud83d\udd28 Setting up the VPS and installing Docker and Sourcegraph First, we need to set up a VPS running Ubuntu 18.04. On this, we'll install Docker and pull the Sourcegraph Docker image. Choose Ubuntu 18.04 (20.04 has some issues installing Docker) and a droplet with enough disk space. Here we chose one that costs $40/month \u2013 but choose a smaller one if you know you only have a few repositories. Further down, select a region that is close to you, set up an SSH key and give your server a friendly name like sourcegraph-server . Finally, click \"Create\" and wait a few seconds until you get your IP address and can connect to the server. \u2692\ufe0f Configuring the VPS We're going to just use the default root user which has some security implications but as we are not going to use this server for anything except Sourcegraph, these are not major. If you prefer to set everything up as a non-root user, you'll need to prefix most of the Linux commands with sudo . Connect to your instance with SSH, substituting the IP address you got from DigitalOcean. ssh root@68.183.10.58 Install Docker by running: snap install docker Open a Tmux pane (where we'll leave Sourcegraph running) by typing tmux . Now pull the Sourcegraph Docker container by running (check for an updated version of this command at https://about.sourcegraph.com/get-started). docker run --publish 7080:7080 --publish 127.0.0.1:3370:3370 --rm --volume ~/.sourcegraph/config:/etc/sourcegraph --volume ~/.sourcegraph/data:/var/opt/sourcegraph sourcegraph/server:3.24.1 It will take half a minute or so to pull the dependencies and initialise Sourcegraph and then you'll see Sourcegraph running on port 7080. Press Ctrl-B and then tap d to detach the Tmux session. This will leave Sourcegraph running in the background even after you close the SSH sessions. If you want to test it out at this stage, open a new SSH connection to your server along with a local portforward (substituting your DigitalOcean IP address again) ssh -L 7080:localhost:7080 root@68.183.10.58 This will forward your local port 7080 through SSH to connect to localhost:7080 on the DigitalOcean instance where Sourcegraph is running. On your local machine, you can now visit http://localhost:7080 in your browser and you should see the Sourcegraph welcome page. Don't sign up yet \u2013 let's first set up a proper connection using a custom domain and SSL. \ud83d\udc49 Pointing a Domain at your Droplet We could access our server by typing in the IP address, but it's hard to remember and we can't easily get an SSL certificate to access our code securely over HTTPS this way. Instead, we'll point a subdomain of a domain we control \u2013 e.g. sg.example.com at the DigitalOcean droplet so that we can access the Sourcegraph server by visiting this domain. In your DNS control panel, add an \"A\" record that points a subdomain to the IP address (the same one you used to connect to your VPS via SSH). In NameCheap, this looks as follows, but this will change depending on your domain registrar or DNS provider: Save the changes and wait for the DNS record to propagate. This can take up to 72 hours, but in practice usually takes less than 5 minutes. \u2328\ufe0f Installing Nginx and configuring a reverse proxy Instead of having users connect directly to the port opened by Docker, we're going to set up Nginx as a scalable web server in front of Docker. Nginx will be responsible for responding to all requests from end users and proxying them over to our Docker connection. apt update && apt install nginx Once installed, you should be able to visit the subdomain we configured in the previous step sg.example.com and see the Nginx default welcome page. Configuring Nginx To configure Nginx as a proxy to the Docker container, we'll need to edit the file at /etc/nginx/sites-available/default . Open this with Nano (or vim if you prefer) by running: nano /etc/nginx/sites-available/default Remove everything in the file and add the below in its place. Substitute both instances of sg.example.com with the subdomain that you set up in the previous step. server { server_name sg.example.com; access_log /var/log/nginx/sourcegraph.access.log; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://localhost:7080; proxy_read_timeout 90; proxy_redirect http://localhost:7080 https://sg.example.com; } listen 80; } This links up the running Docker container with Nginx, meaning that any traffic that comes in on our sg.example.com subdomain will be redirected to the Sourcegraph server running inside Docker. Save the file and run: service nginx reload You should now be able to see the same Source Welcome page running on http://sg.example.com . Note that the secure version ( https ) will not work yet, as we still need to set up an SSL certificate. \ud83c\udfab Getting an SSL certificate with LetsEncrypt Install certbot using snap by running the following command: snap install --classic certbot snap install --classic certbot Then run: certbot And follow the prompts to: Enter your email address. Agree to the terms of use. Opt in or out of communications from the EFF. Select the sg.example.com domain. Certbot will automatically modify the Nginx config file that we edited earlier to use https instead of http . Visit https://sg.example.com and now you can finally fill out the form to sign up for Sourcegraph. \u270f\ufe0f Configuring Sourcegraph with the custom domain and GitHub Sourcegraph is very configurable and has many different options. The two most important ones to get started with using it are: Tell Sourcegraph where it is hosted. Tell Sourcegraph where to find your code. Configuring the domain Visit https://sg.ritza.co/site-admin/configuration and uncomment the third line (remove the // at the start). Then replace the domain with the subdomain that we chose earlier. Press the green \"Save Changes\" button and choose \"Restart Server\" when prompted. Linking to GitHub To fetch your code from GitHub, you need to get a token from GitHub. Log into your GitHub account and visit https://github.com/settings/tokens . Click \"Generate new token\" and follow the prompts. You'll only see your token once so save it somewhere safe and secure such as a password manager. Now navigate to https://sg.ritza.co/site-admin/external-services/new and choose GitHub. Modify the configuration to: Add your GitHub token. Add any organizations for which you want to clone and index all repositories. Add any individual repositories that you want to clone and index. For example, in the configuration below, we clone all public repositories from google and all public and private repositories from ritza-co (in our example, the GitHub token has access to the whole ritza-co org). We also add repositories for React and Tensorflow individually. { \"url\": \"https://github.com\", \"token\": \"e10db0e8307726f57254875992c24dd7ca2e2b23\", \"orgs\": [\"google\", \"ritza-co\"], \"repos\": [\"facebook/react\", \"tensorflow/tensorflow\"] } Click the blue \"Add repositories\" button below the text box and wait for Sourcegraph to clone and index your repositories. \ud83d\udd0e Running your first Sourcegraph search While it's doing that, you can go ahead and try out your first Sourcegraph search (which might be incomplete while the repos are still cloning). For example, below you can see all empty print statements in Python files across all code. Unlike GitHub search, it respects the specials characters and only returns matches including the () . It also has easy options to exclude or include forks, match case, and a lot more besides. Take a look at https://docs.sourcegraph.com/code_search/tutorials/examples for some example searches and to start getting to know the syntax.","title":"The opinionated guide to setting up a Sourcegraph server for advanced code search"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-advanced-code-search","text":"If you've ever written code, you probably know that: \ud83d\udd0d Searching through examples of code is useful for so many things. \ud83e\udd26\u200d\u2642\ufe0f GitHub search kind of sucks. You might not have tried out advanced code search tools like Sourcegraph because getting started looks like too much effort. The Sourcegraph \"Getting Started\" page already has a ton of information about different ways to start using Sourcegraph, but here we'll go through an opinionated set up guide. Specifically, we'll: \u2601\ufe0f Set up Sourcegraph on a VPS (DigitalOcean in this case, but feel free to use your own cloud provider). \ud83d\ude8d Set up Nginx as reverse proxy. \ud83c\udfab Use LetsEncrypt to get an SSL certificate. \ud83d\udc69\u200d\ud83d\udcbb Integrate with GitHub to search through public and private repositories hosted there. This is a tradeoff between running Sourcegraph locally on your dev machine (where features would be limited), and installing it to a cluster (where set up would take longer).","title":"The opinionated guide to setting up a Sourcegraph server for advanced code search"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#the-end-result-of-following-this-guide","text":"At the end of this guide, you'll have your own Sourcegraph server set up on a custom domain like sg.example.com . It will periodically fetch any repositories you are interested in from GitHub (private, public, or from your entire GitHub org) and update its index so that you have these at your fingertips. You'll be able to search through all your code using advanced syntax and better defaults.","title":"\ud83d\uddbc The end result of following this guide"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#requirements-to-follow-along","text":"To follow along, you should: \ud83d\udcbb Be comfortable using Linux and SSH, connecting to a VPS and installing and configuring software. \ud83c\udf10 Have a custom domain where you can add new subdomains, e.g. through NameCheap or similar. \u2601\ufe0f Have an account at a cloud provider, such as DigitalOcean or AWS.","title":"\u2611\ufe0f Requirements to follow along"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#setting-up-the-vps-and-installing-docker-and-sourcegraph","text":"First, we need to set up a VPS running Ubuntu 18.04. On this, we'll install Docker and pull the Sourcegraph Docker image. Choose Ubuntu 18.04 (20.04 has some issues installing Docker) and a droplet with enough disk space. Here we chose one that costs $40/month \u2013 but choose a smaller one if you know you only have a few repositories. Further down, select a region that is close to you, set up an SSH key and give your server a friendly name like sourcegraph-server . Finally, click \"Create\" and wait a few seconds until you get your IP address and can connect to the server.","title":"\ud83d\udd28 Setting up the VPS and installing Docker and Sourcegraph"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#configuring-the-vps","text":"We're going to just use the default root user which has some security implications but as we are not going to use this server for anything except Sourcegraph, these are not major. If you prefer to set everything up as a non-root user, you'll need to prefix most of the Linux commands with sudo . Connect to your instance with SSH, substituting the IP address you got from DigitalOcean. ssh root@68.183.10.58 Install Docker by running: snap install docker Open a Tmux pane (where we'll leave Sourcegraph running) by typing tmux . Now pull the Sourcegraph Docker container by running (check for an updated version of this command at https://about.sourcegraph.com/get-started). docker run --publish 7080:7080 --publish 127.0.0.1:3370:3370 --rm --volume ~/.sourcegraph/config:/etc/sourcegraph --volume ~/.sourcegraph/data:/var/opt/sourcegraph sourcegraph/server:3.24.1 It will take half a minute or so to pull the dependencies and initialise Sourcegraph and then you'll see Sourcegraph running on port 7080. Press Ctrl-B and then tap d to detach the Tmux session. This will leave Sourcegraph running in the background even after you close the SSH sessions. If you want to test it out at this stage, open a new SSH connection to your server along with a local portforward (substituting your DigitalOcean IP address again) ssh -L 7080:localhost:7080 root@68.183.10.58 This will forward your local port 7080 through SSH to connect to localhost:7080 on the DigitalOcean instance where Sourcegraph is running. On your local machine, you can now visit http://localhost:7080 in your browser and you should see the Sourcegraph welcome page. Don't sign up yet \u2013 let's first set up a proper connection using a custom domain and SSL.","title":"\u2692\ufe0f Configuring the VPS"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#pointing-a-domain-at-your-droplet","text":"We could access our server by typing in the IP address, but it's hard to remember and we can't easily get an SSL certificate to access our code securely over HTTPS this way. Instead, we'll point a subdomain of a domain we control \u2013 e.g. sg.example.com at the DigitalOcean droplet so that we can access the Sourcegraph server by visiting this domain. In your DNS control panel, add an \"A\" record that points a subdomain to the IP address (the same one you used to connect to your VPS via SSH). In NameCheap, this looks as follows, but this will change depending on your domain registrar or DNS provider: Save the changes and wait for the DNS record to propagate. This can take up to 72 hours, but in practice usually takes less than 5 minutes.","title":"\ud83d\udc49 Pointing a Domain at your Droplet"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#installing-nginx-and-configuring-a-reverse-proxy","text":"Instead of having users connect directly to the port opened by Docker, we're going to set up Nginx as a scalable web server in front of Docker. Nginx will be responsible for responding to all requests from end users and proxying them over to our Docker connection. apt update && apt install nginx Once installed, you should be able to visit the subdomain we configured in the previous step sg.example.com and see the Nginx default welcome page.","title":"\u2328\ufe0f Installing Nginx and configuring a reverse proxy"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#configuring-nginx","text":"To configure Nginx as a proxy to the Docker container, we'll need to edit the file at /etc/nginx/sites-available/default . Open this with Nano (or vim if you prefer) by running: nano /etc/nginx/sites-available/default Remove everything in the file and add the below in its place. Substitute both instances of sg.example.com with the subdomain that you set up in the previous step. server { server_name sg.example.com; access_log /var/log/nginx/sourcegraph.access.log; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://localhost:7080; proxy_read_timeout 90; proxy_redirect http://localhost:7080 https://sg.example.com; } listen 80; } This links up the running Docker container with Nginx, meaning that any traffic that comes in on our sg.example.com subdomain will be redirected to the Sourcegraph server running inside Docker. Save the file and run: service nginx reload You should now be able to see the same Source Welcome page running on http://sg.example.com . Note that the secure version ( https ) will not work yet, as we still need to set up an SSL certificate.","title":"Configuring Nginx"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#getting-an-ssl-certificate-with-letsencrypt","text":"Install certbot using snap by running the following command: snap install --classic certbot snap install --classic certbot Then run: certbot And follow the prompts to: Enter your email address. Agree to the terms of use. Opt in or out of communications from the EFF. Select the sg.example.com domain. Certbot will automatically modify the Nginx config file that we edited earlier to use https instead of http . Visit https://sg.example.com and now you can finally fill out the form to sign up for Sourcegraph.","title":"\ud83c\udfab Getting an SSL certificate with LetsEncrypt"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#configuring-sourcegraph-with-the-custom-domain-and-github","text":"Sourcegraph is very configurable and has many different options. The two most important ones to get started with using it are: Tell Sourcegraph where it is hosted. Tell Sourcegraph where to find your code.","title":"\u270f\ufe0f Configuring Sourcegraph with the custom domain and GitHub"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#configuring-the-domain","text":"Visit https://sg.ritza.co/site-admin/configuration and uncomment the third line (remove the // at the start). Then replace the domain with the subdomain that we chose earlier. Press the green \"Save Changes\" button and choose \"Restart Server\" when prompted.","title":"Configuring the domain"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#linking-to-github","text":"To fetch your code from GitHub, you need to get a token from GitHub. Log into your GitHub account and visit https://github.com/settings/tokens . Click \"Generate new token\" and follow the prompts. You'll only see your token once so save it somewhere safe and secure such as a password manager. Now navigate to https://sg.ritza.co/site-admin/external-services/new and choose GitHub. Modify the configuration to: Add your GitHub token. Add any organizations for which you want to clone and index all repositories. Add any individual repositories that you want to clone and index. For example, in the configuration below, we clone all public repositories from google and all public and private repositories from ritza-co (in our example, the GitHub token has access to the whole ritza-co org). We also add repositories for React and Tensorflow individually. { \"url\": \"https://github.com\", \"token\": \"e10db0e8307726f57254875992c24dd7ca2e2b23\", \"orgs\": [\"google\", \"ritza-co\"], \"repos\": [\"facebook/react\", \"tensorflow/tensorflow\"] } Click the blue \"Add repositories\" button below the text box and wait for Sourcegraph to clone and index your repositories.","title":"Linking to GitHub"},{"location":"the-opinionated-guide-to-setting-up-a-sourcegraph-server-for-more-productive-advanced-code-search/#running-your-first-sourcegraph-search","text":"While it's doing that, you can go ahead and try out your first Sourcegraph search (which might be incomplete while the repos are still cloning). For example, below you can see all empty print statements in Python files across all code. Unlike GitHub search, it respects the specials characters and only returns matches including the () . It also has easy options to exclude or include forks, match case, and a lot more besides. Take a look at https://docs.sourcegraph.com/code_search/tutorials/examples for some example searches and to start getting to know the syntax.","title":"\ud83d\udd0e Running your first Sourcegraph search"}]}